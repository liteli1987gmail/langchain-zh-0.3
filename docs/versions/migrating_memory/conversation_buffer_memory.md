---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/versions/migrating_memory/conversation_buffer_memory.ipynb
---
# ä» ConversationBufferMemory æˆ– ConversationStringBufferMemory è¿ç§»

[ConversationBufferMemory](https://python.langchain.com/api_reference/langchain/memory/langchain.memory.buffer.ConversationBufferMemory.html)
å’Œ [ConversationStringBufferMemory](https://python.langchain.com/api_reference/langchain/memory/langchain.memory.buffer.ConversationStringBufferMemory.html)
ç”¨äºè·Ÿè¸ªäººç±»ä¸ AI åŠ©æ‰‹ä¹‹é—´çš„å¯¹è¯ï¼Œè€Œæ— éœ€ä»»ä½•é¢å¤–å¤„ç†ã€‚


:::note
`ConversationStringBufferMemory` ç›¸å½“äº `ConversationBufferMemory`ï¼Œä½†é’ˆå¯¹çš„æ˜¯ä¸æ˜¯èŠå¤©æ¨¡å‹çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚
:::

ä½¿ç”¨ç°æœ‰ç°ä»£åŸè¯­å¤„ç†å¯¹è¯å†å²çš„æ–¹æ³•æœ‰ï¼š

1. ä½¿ç”¨ [LangGraph æŒä¹…åŒ–](https://langchain-ai.github.io/langgraph/how-tos/persistence/) ä»¥åŠå¯¹æ¶ˆæ¯å†å²çš„é€‚å½“å¤„ç†
2. ä½¿ç”¨ LCEL ä¸ [RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html#) ç»“åˆå¯¹æ¶ˆæ¯å†å²çš„é€‚å½“å¤„ç†ã€‚

å¤§å¤šæ•°ç”¨æˆ·ä¼šå‘ç° [LangGraph æŒä¹…åŒ–](https://langchain-ai.github.io/langgraph/how-tos/persistence/) æ¯”ç­‰æ•ˆçš„ LCEL æ›´æ˜“äºä½¿ç”¨å’Œé…ç½®ï¼Œç‰¹åˆ«æ˜¯å¯¹äºæ›´å¤æ‚çš„ç”¨ä¾‹ã€‚

## è®¾ç½®


```python
%%capture --no-stderr
%pip install --upgrade --quiet langchain-openai langchain
```


```python
import os
from getpass import getpass

if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"] = getpass()
```

## ä¸LLMChain / ConversationChainçš„ä½¿ç”¨

æœ¬èŠ‚å±•ç¤ºå¦‚ä½•ä»ä¸`LLMChain`æˆ–`ConversationChain`ä¸€èµ·ä½¿ç”¨çš„`ConversationBufferMemory`æˆ–`ConversationStringBufferMemory`è¿ç§»ã€‚

### æ—§ç‰ˆ

ä»¥ä¸‹æ˜¯`ConversationBufferMemory`ä¸`LLMChain`æˆ–ç­‰æ•ˆçš„`ConversationChain`çš„ç¤ºä¾‹ç”¨æ³•ã€‚

<details open>


```python
<!--IMPORTS:[{"imported": "LLMChain", "source": "langchain.chains", "docs": "https://python.langchain.com/api_reference/langchain/chains/langchain.chains.llm.LLMChain.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}, {"imported": "ConversationBufferMemory", "source": "langchain.memory", "docs": "https://python.langchain.com/api_reference/langchain/memory/langchain.memory.buffer.ConversationBufferMemory.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}, {"imported": "SystemMessage", "source": "langchain_core.messages", "docs": "https://python.langchain.com/api_reference/core/messages/langchain_core.messages.system.SystemMessage.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts.chat", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}, {"imported": "HumanMessagePromptTemplate", "source": "langchain_core.prompts.chat", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.HumanMessagePromptTemplate.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}, {"imported": "MessagesPlaceholder", "source": "langchain_core.prompts.chat", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.MessagesPlaceholder.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}]-->
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory
from langchain_core.messages import SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.prompts.chat import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
)
from langchain_openai import ChatOpenAI

prompt = ChatPromptTemplate(
    [
        MessagesPlaceholder(variable_name="chat_history"),
        HumanMessagePromptTemplate.from_template("{text}"),
    ]
)

# highlight-start
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
# highlight-end

legacy_chain = LLMChain(
    llm=ChatOpenAI(),
    prompt=prompt,
    # highlight-next-line
    memory=memory,
)

legacy_result = legacy_chain.invoke({"text": "my name is bob"})
print(legacy_result)

legacy_result = legacy_chain.invoke({"text": "what was my name"})
```
```output
{'text': 'Hello Bob! How can I assist you today?', 'chat_history': [HumanMessage(content='my name is bob', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello Bob! How can I assist you today?', additional_kwargs={}, response_metadata={})]}
```

```python
legacy_result["text"]
```



```output
'Your name is Bob. How can I assist you today, Bob?'
```


:::note
è¯·æ³¨æ„ï¼Œå•ä¸ªå†…å­˜å¯¹è±¡ä¸­ä¸æ”¯æŒåˆ†ç¦»å¯¹è¯çº¿ç¨‹
:::

</details>

### LangGraph

ä¸‹é¢çš„ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨LangGraphå®ç°å¸¦æœ‰`ConversationBufferMemory`çš„`ConversationChain`æˆ–`LLMChain`ã€‚

æœ¬ç¤ºä¾‹å‡è®¾æ‚¨å¯¹`LangGraph`å·²æœ‰ä¸€å®šäº†è§£ã€‚å¦‚æœæ‚¨ä¸ç†Ÿæ‚‰ï¼Œè¯·å‚é˜…[LangGraphå¿«é€Ÿå…¥é—¨æŒ‡å—](https://langchain-ai.github.io/langgraph/tutorials/introduction/)ä»¥è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

`LangGraph`æä¾›äº†è®¸å¤šé¢å¤–åŠŸèƒ½ï¼ˆä¾‹å¦‚ï¼Œæ—¶é—´æ—…è¡Œå’Œä¸­æ–­ï¼‰ï¼Œå¹¶ä¸”é€‚ç”¨äºå…¶ä»–æ›´å¤æ‚ï¼ˆå’Œç°å®ï¼‰çš„æ¶æ„ã€‚

<details open>


```python
<!--IMPORTS:[{"imported": "HumanMessage", "source": "langchain_core.messages", "docs": "https://python.langchain.com/api_reference/core/messages/langchain_core.messages.human.HumanMessage.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}]-->
import uuid

from IPython.display import Image, display
from langchain_core.messages import HumanMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import START, MessagesState, StateGraph

# Define a new graph
workflow = StateGraph(state_schema=MessagesState)

# Define a chat model
model = ChatOpenAI()


# Define the function that calls the model
def call_model(state: MessagesState):
    response = model.invoke(state["messages"])
    # We return a list, because this will get added to the existing list
    return {"messages": response}


# Define the two nodes we will cycle between
workflow.add_edge(START, "model")
workflow.add_node("model", call_model)


# Adding memory is straight forward in langgraph!
# highlight-next-line
memory = MemorySaver()

app = workflow.compile(
    # highlight-next-line
    checkpointer=memory
)


# The thread id is a unique key that identifies
# this particular conversation.
# We'll just generate a random uuid here.
# This enables a single application to manage conversations among multiple users.
thread_id = uuid.uuid4()
# highlight-next-line
config = {"configurable": {"thread_id": thread_id}}


input_message = HumanMessage(content="hi! I'm bob")
for event in app.stream({"messages": [input_message]}, config, stream_mode="values"):
    event["messages"][-1].pretty_print()

# Here, let's confirm that the AI remembers our name!
input_message = HumanMessage(content="what was my name?")
for event in app.stream({"messages": [input_message]}, config, stream_mode="values"):
    event["messages"][-1].pretty_print()
```
```output
================================[1m Human Message [0m=================================

hi! I'm bob
==================================[1m Ai Message [0m==================================

Hello Bob! How can I assist you today?
================================[1m Human Message [0m=================================

what was my name?
==================================[1m Ai Message [0m==================================

Your name is Bob. How can I help you today, Bob?
```
</details>

### LCEL RunnableWithMessageHistory

æˆ–è€…ï¼Œå¦‚æœæ‚¨æœ‰ä¸€ä¸ªç®€å•çš„é“¾ï¼Œå¯ä»¥å°†é“¾çš„èŠå¤©æ¨¡å‹åŒ…è£…åœ¨ [RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html) ä¸­ã€‚

æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…ä»¥ä¸‹ [è¿ç§»æŒ‡å—](/docs/versions/migrating_chains/conversation_chain/)ã€‚


## ä¸é¢„æ„å»ºä»£ç†çš„ä½¿ç”¨

æ­¤ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ä½¿ç”¨ [create_tool_calling_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html) å‡½æ•°æ„å»ºçš„é¢„æ„å»ºä»£ç†çš„ä»£ç†æ‰§è¡Œå™¨ã€‚

å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨å…¶ä¸­ä¸€ä¸ª [æ—§çš„ LangChain é¢„æ„å»ºä»£ç†](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/)ï¼Œæ‚¨åº”è¯¥èƒ½å¤Ÿ
ç”¨æ–°çš„ [langgraph é¢„æ„å»ºä»£ç†](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/) æ›¿æ¢è¯¥ä»£ç ï¼Œè¯¥ä»£ç†åˆ©ç”¨
èŠå¤©æ¨¡å‹çš„åŸç”Ÿå·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œå¹¶ä¸”å¯èƒ½ä¼šæ›´å¥½åœ°å¼€ç®±å³ç”¨ã€‚

### æ—§ç‰ˆç”¨æ³•

<details open>


```python
<!--IMPORTS:[{"imported": "AgentExecutor", "source": "langchain.agents", "docs": "https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}, {"imported": "create_tool_calling_agent", "source": "langchain.agents", "docs": "https://python.langchain.com/api_reference/langchain/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}, {"imported": "ConversationBufferMemory", "source": "langchain.memory", "docs": "https://python.langchain.com/api_reference/langchain/memory/langchain.memory.buffer.ConversationBufferMemory.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}, {"imported": "tool", "source": "langchain_core.tools", "docs": "https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}]-->
from langchain import hub
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain.memory import ConversationBufferMemory
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

model = ChatOpenAI(temperature=0)


@tool
def get_user_age(name: str) -> str:
    """Use this tool to find the user's age."""
    # This is a placeholder for the actual implementation
    if "bob" in name.lower():
        return "42 years old"
    return "41 years old"


tools = [get_user_age]

prompt = ChatPromptTemplate.from_messages(
    [
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)

# Construct the Tools agent
agent = create_tool_calling_agent(model, tools, prompt)
# Instantiate memory
# highlight-start
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
# highlight-end

# Create an agent
agent = create_tool_calling_agent(model, tools, prompt)
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    # highlight-next-line
    memory=memory,  # Pass the memory to the executor
)

# Verify that the agent can use tools
print(agent_executor.invoke({"input": "hi! my name is bob what is my age?"}))
print()
# Verify that the agent has access to conversation history.
# The agent should be able to answer that the user's name is bob.
print(agent_executor.invoke({"input": "do you remember my name?"}))
```
```output
{'input': 'hi! my name is bob what is my age?', 'chat_history': [HumanMessage(content='hi! my name is bob what is my age?', additional_kwargs={}, response_metadata={}), AIMessage(content='Bob, you are 42 years old.', additional_kwargs={}, response_metadata={})], 'output': 'Bob, you are 42 years old.'}

{'input': 'do you remember my name?', 'chat_history': [HumanMessage(content='hi! my name is bob what is my age?', additional_kwargs={}, response_metadata={}), AIMessage(content='Bob, you are 42 years old.', additional_kwargs={}, response_metadata={}), HumanMessage(content='do you remember my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, your name is Bob.', additional_kwargs={}, response_metadata={})], 'output': 'Yes, your name is Bob.'}
```
</details>

### LangGraph

æ‚¨å¯ä»¥æŒ‰ç…§æ ‡å‡† LangChain æ•™ç¨‹ [æ„å»ºä»£ç†](/docs/tutorials/agents/) æ¥æ·±å…¥äº†è§£å…¶å·¥ä½œåŸç†ã€‚

è¿™ä¸ªç¤ºä¾‹åœ¨è¿™é‡Œæ˜ç¡®å±•ç¤ºï¼Œä»¥ä¾¿ç”¨æˆ·æ›´å®¹æ˜“æ¯”è¾ƒä¼ ç»Ÿå®ç°ä¸ç›¸åº”çš„LangGraphå®ç°ã€‚

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åœ¨LangGraphä¸­ä¸º[é¢„æ„å»ºçš„Reactä»£ç†](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent)æ·»åŠ è®°å¿†ã€‚

æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…LangGraphä¸­çš„[å¦‚ä½•ä¸ºé¢„æ„å»ºçš„ReActä»£ç†æ·»åŠ è®°å¿†](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-memory/)æŒ‡å—ã€‚

<details open>


```python
<!--IMPORTS:[{"imported": "HumanMessage", "source": "langchain_core.messages", "docs": "https://python.langchain.com/api_reference/core/messages/langchain_core.messages.human.HumanMessage.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}, {"imported": "tool", "source": "langchain_core.tools", "docs": "https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "Migrating off ConversationBufferMemory or ConversationStringBufferMemory"}]-->
import uuid

from langchain_core.messages import HumanMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import create_react_agent


@tool
def get_user_age(name: str) -> str:
    """Use this tool to find the user's age."""
    # This is a placeholder for the actual implementation
    if "bob" in name.lower():
        return "42 years old"
    return "41 years old"


# highlight-next-line
memory = MemorySaver()
model = ChatOpenAI()
app = create_react_agent(
    model,
    tools=[get_user_age],
    # highlight-next-line
    checkpointer=memory,
)

# highlight-start
# The thread id is a unique key that identifies
# this particular conversation.
# We'll just generate a random uuid here.
# This enables a single application to manage conversations among multiple users.
thread_id = uuid.uuid4()
config = {"configurable": {"thread_id": thread_id}}
# highlight-end

# Tell the AI that our name is Bob, and ask it to use a tool to confirm
# that it's capable of working like an agent.
input_message = HumanMessage(content="hi! I'm bob. What is my age?")

for event in app.stream({"messages": [input_message]}, config, stream_mode="values"):
    event["messages"][-1].pretty_print()

# Confirm that the chat bot has access to previous conversation
# and can respond to the user saying that the user's name is Bob.
input_message = HumanMessage(content="do you remember my name?")

for event in app.stream({"messages": [input_message]}, config, stream_mode="values"):
    event["messages"][-1].pretty_print()
```
```output
================================[1m Human Message [0m=================================

hi! I'm bob. What is my age?
==================================[1m Ai Message [0m==================================
Tool Calls:
  get_user_age (call_oEDwEbIDNdokwqhAV6Azn47c)
 Call ID: call_oEDwEbIDNdokwqhAV6Azn47c
  Args:
    name: bob
=================================[1m Tool Message [0m=================================
Name: get_user_age

42 years old
==================================[1m Ai Message [0m==================================

Bob, you are 42 years old! If you need any more assistance or information, feel free to ask.
================================[1m Human Message [0m=================================

do you remember my name?
==================================[1m Ai Message [0m==================================

Yes, your name is Bob. If you have any other questions or need assistance, feel free to ask!
```
å¦‚æœæˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„çº¿ç¨‹IDï¼Œå®ƒå°†å¼€å§‹ä¸€ä¸ªæ–°çš„å¯¹è¯ï¼Œæœºå™¨äººå°†ä¸çŸ¥é“æˆ‘ä»¬çš„åå­—ï¼


```python
config = {"configurable": {"thread_id": "123456789"}}

input_message = HumanMessage(content="hi! do you remember my name?")

for event in app.stream({"messages": [input_message]}, config, stream_mode="values"):
    event["messages"][-1].pretty_print()
```
```output
================================[1m Human Message [0m=================================

hi! do you remember my name?
==================================[1m Ai Message [0m==================================

Hello! Yes, I remember your name. It's great to see you again! How can I assist you today?
```
</details>

## ä¸‹ä¸€æ­¥

æ¢ç´¢ä¸LangGraphçš„æŒä¹…æ€§ï¼š

* [LangGraphå¿«é€Ÿå…¥é—¨æ•™ç¨‹](https://langchain-ai.github.io/langgraph/tutorials/introduction/)
* [å¦‚ä½•ä¸ºæ‚¨çš„å›¾æ·»åŠ æŒä¹…æ€§ï¼ˆâ€œè®°å¿†â€ï¼‰](https://langchain-ai.github.io/langgraph/how-tos/persistence/)
* [å¦‚ä½•ç®¡ç†å¯¹è¯å†å²](https://langchain-ai.github.io/langgraph/how-tos/memory/manage-conversation-history/)
* [å¦‚ä½•æ·»åŠ å¯¹è¯å†å²çš„æ‘˜è¦](https://langchain-ai.github.io/langgraph/how-tos/memory/add-summary-conversation-history/)

ä½¿ç”¨ç®€å•çš„ LCEL æ·»åŠ æŒä¹…æ€§ï¼ˆå¯¹äºæ›´å¤æ‚çš„ç”¨ä¾‹ï¼Œå»ºè®®ä½¿ç”¨ langgraphï¼‰ï¼š

* [å¦‚ä½•æ·»åŠ æ¶ˆæ¯å†å²](/docs/how_to/message_history/)

å¤„ç†æ¶ˆæ¯å†å²ï¼š

* [å¦‚ä½•ä¿®å‰ªæ¶ˆæ¯](/docs/how_to/trim_messages)
* [å¦‚ä½•è¿‡æ»¤æ¶ˆæ¯](/docs/how_to/filter_messages/)
* [å¦‚ä½•åˆå¹¶æ¶ˆæ¯è¿è¡Œ](/docs/how_to/merge_message_runs/)

