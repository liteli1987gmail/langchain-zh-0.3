---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/how_to/tools_prompting.ipynb
sidebar_position: 3
---
# å¦‚ä½•ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹å’ŒèŠå¤©æ¨¡å‹æ·»åŠ ä¸´æ—¶å·¥å…·è°ƒç”¨èƒ½åŠ›

:::caution

ä¸€äº›æ¨¡å‹å·²ç»é’ˆå¯¹å·¥å…·è°ƒç”¨è¿›è¡Œäº†å¾®è°ƒï¼Œå¹¶æä¾›äº†ä¸“ç”¨çš„å·¥å…·è°ƒç”¨APIã€‚é€šå¸¸ï¼Œè¿™äº›æ¨¡å‹åœ¨å·¥å…·è°ƒç”¨æ–¹é¢ä¼˜äºæœªå¾®è°ƒçš„æ¨¡å‹ï¼Œæ¨èç”¨äºéœ€è¦å·¥å…·è°ƒç”¨çš„ç”¨ä¾‹ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[å¦‚ä½•ä½¿ç”¨èŠå¤©æ¨¡å‹è°ƒç”¨å·¥å…·](/docs/how_to/tool_calling)æŒ‡å—ã€‚

:::

:::info Prerequisites

æœ¬æŒ‡å—å‡è®¾æ‚¨ç†Ÿæ‚‰ä»¥ä¸‹æ¦‚å¿µï¼š

- [LangChain å·¥å…·](/docs/concepts/#tools)
- [å‡½æ•°/å·¥å…·è°ƒç”¨](https://python.langchain.com/docs/concepts/#functiontool-calling)
- [èŠå¤©æ¨¡å‹](/docs/concepts/#chat-models)
- [å¤§å‹è¯­è¨€æ¨¡å‹](/docs/concepts/#llms)

:::

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä¸ºèŠå¤©æ¨¡å‹æ·»åŠ **ä¸´æ—¶**å·¥å…·è°ƒç”¨æ”¯æŒã€‚è¿™æ˜¯ä¸€ç§è°ƒç”¨å·¥å…·çš„æ›¿ä»£æ–¹æ³•ï¼Œé€‚ç”¨äºä½¿ç”¨ä¸åŸç”Ÿæ”¯æŒ[å·¥å…·è°ƒç”¨](/docs/how_to/tool_calling)çš„æ¨¡å‹ã€‚

æˆ‘ä»¬å°†é€šè¿‡ç®€å•åœ°ç¼–å†™ä¸€ä¸ªæç¤ºæ¥å®ç°è¿™ä¸€ç‚¹ï¼Œä»¥ä½¿æ¨¡å‹è°ƒç”¨é€‚å½“çš„å·¥å…·ã€‚ä»¥ä¸‹æ˜¯é€»è¾‘çš„ç¤ºæ„å›¾ï¼š

![chain](../../static/img/tool_chain.svg)

## è®¾ç½®

æˆ‘ä»¬éœ€è¦å®‰è£…ä»¥ä¸‹è½¯ä»¶åŒ…ï¼š


```python
%pip install --upgrade --quiet langchain langchain-community
```

å¦‚æœæ‚¨æƒ³ä½¿ç”¨LangSmithï¼Œè¯·å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šï¼š


```python
import getpass
import os
# os.environ["LANGCHAIN_TRACING_V2"] = "true"
# os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()
```

æ‚¨å¯ä»¥é€‰æ‹©æœ¬æŒ‡å—ä¸­æä¾›çš„ä»»ä½•æ¨¡å‹ã€‚è¯·è®°ä½ï¼Œè¿™äº›æ¨¡å‹å¤§å¤šæ•°å·²ç»[æ”¯æŒåŸç”Ÿå·¥å…·è°ƒç”¨](/docs/integrations/chat/)ï¼Œå› æ­¤åœ¨è¿™äº›æ¨¡å‹ä¸­ä½¿ç”¨è¿™é‡Œå±•ç¤ºçš„æç¤ºç­–ç•¥æ˜¯æ²¡æœ‰æ„ä¹‰çš„ï¼Œæ‚¨åº”è¯¥éµå¾ª[å¦‚ä½•ä½¿ç”¨èŠå¤©æ¨¡å‹è°ƒç”¨å·¥å…·](/docs/how_to/tool_calling)æŒ‡å—ã€‚

import ChatModelTabs from "@theme/ChatModelTabs";

<ChatModelTabs openaiParams={`model="gpt-4"`} />

ä¸ºäº†è¯´æ˜è¿™ä¸ªæƒ³æ³•ï¼Œæˆ‘ä»¬å°†é€šè¿‡Ollamaä½¿ç”¨`phi3`ï¼Œå®ƒ**ä¸**æ”¯æŒåŸç”Ÿå·¥å…·è°ƒç”¨ã€‚å¦‚æœæ‚¨ä¹Ÿæƒ³ä½¿ç”¨`Ollama`ï¼Œè¯·éµå¾ª[è¿™äº›è¯´æ˜](/docs/integrations/chat/ollama/)ã€‚


```python
<!--IMPORTS:[{"imported": "Ollama", "source": "langchain_community.llms", "docs": "https://python.langchain.com/api_reference/community/llms/langchain_community.llms.ollama.Ollama.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}]-->
from langchain_community.llms import Ollama

model = Ollama(model="phi3")
```

## åˆ›å»ºä¸€ä¸ªå·¥å…·

é¦–å…ˆï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª`add`å’Œ`multiply`å·¥å…·ã€‚æœ‰å…³åˆ›å»ºè‡ªå®šä¹‰å·¥å…·çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§[æœ¬æŒ‡å—](/docs/how_to/custom_tools)ã€‚


```python
<!--IMPORTS:[{"imported": "tool", "source": "langchain_core.tools", "docs": "https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}]-->
from langchain_core.tools import tool


@tool
def multiply(x: float, y: float) -> float:
    """Multiply two numbers together."""
    return x * y


@tool
def add(x: int, y: int) -> int:
    "Add two numbers."
    return x + y


tools = [multiply, add]

# Let's inspect the tools
for t in tools:
    print("--")
    print(t.name)
    print(t.description)
    print(t.args)
```
```output
--
multiply
Multiply two numbers together.
{'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}
--
add
Add two numbers.
{'x': {'title': 'X', 'type': 'integer'}, 'y': {'title': 'Y', 'type': 'integer'}}
```

```python
multiply.invoke({"x": 4, "y": 5})
```



```output
20.0
```


## åˆ›å»ºæˆ‘ä»¬çš„æç¤º

æˆ‘ä»¬æƒ³è¦ç¼–å†™ä¸€ä¸ªæç¤ºï¼ŒæŒ‡å®šæ¨¡å‹å¯ä»¥è®¿é—®çš„å·¥å…·ã€è¿™äº›å·¥å…·çš„å‚æ•°ä»¥åŠæ¨¡å‹çš„æœŸæœ›è¾“å‡ºæ ¼å¼ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†æŒ‡ç¤ºå®ƒè¾“å‡ºä¸€ä¸ªå½¢å¼ä¸º`{"name": "...", "arguments": {...}}`çš„JSONå¯¹è±¡ã€‚


```python
<!--IMPORTS:[{"imported": "JsonOutputParser", "source": "langchain_core.output_parsers", "docs": "https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.json.JsonOutputParser.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}, {"imported": "render_text_description", "source": "langchain_core.tools", "docs": "https://python.langchain.com/api_reference/core/tools/langchain_core.tools.render.render_text_description.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}]-->
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import render_text_description

rendered_tools = render_text_description(tools)
print(rendered_tools)
```
```output
multiply(x: float, y: float) -> float - Multiply two numbers together.
add(x: int, y: int) -> int - Add two numbers.
```

```python
system_prompt = f"""\
You are an assistant that has access to the following set of tools. 
Here are the names and descriptions for each tool:

{rendered_tools}

Given the user input, return the name and input of the tool to use. 
Return your response as a JSON blob with 'name' and 'arguments' keys.

The `arguments` should be a dictionary, with keys corresponding 
to the argument names and the values corresponding to the requested values.
"""

prompt = ChatPromptTemplate.from_messages(
    [("system", system_prompt), ("user", "{input}")]
)
```


```python
chain = prompt | model
message = chain.invoke({"input": "what's 3 plus 1132"})

# Let's take a look at the output from the model
# if the model is an LLM (not a chat model), the output will be a string.
if isinstance(message, str):
    print(message)
else:  # Otherwise it's a chat model
    print(message.content)
```
```output
{
    "name": "add",
    "arguments": {
        "x": 3,
        "y": 1132
    }
}
```
## æ·»åŠ è¾“å‡ºè§£æå™¨

æˆ‘ä»¬å°†ä½¿ç”¨`JsonOutputParser`å°†æ¨¡å‹çš„è¾“å‡ºè§£æä¸ºJSONã€‚


```python
<!--IMPORTS:[{"imported": "JsonOutputParser", "source": "langchain_core.output_parsers", "docs": "https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.json.JsonOutputParser.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}]-->
from langchain_core.output_parsers import JsonOutputParser

chain = prompt | model | JsonOutputParser()
chain.invoke({"input": "what's thirteen times 4"})
```



```output
{'name': 'multiply', 'arguments': {'x': 13.0, 'y': 4.0}}
```


:::important

ğŸ‰ å¤ªæ£’äº†ï¼ ğŸ‰ æˆ‘ä»¬ç°åœ¨å·²ç»æŒ‡ç¤ºæˆ‘ä»¬çš„æ¨¡å‹å¦‚ä½•**è¯·æ±‚**è°ƒç”¨ä¸€ä¸ªå·¥å…·ã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€äº›é€»è¾‘æ¥å®é™…è¿è¡Œå·¥å…·ï¼
:::

## è°ƒç”¨å·¥å…· ğŸƒ

ç°åœ¨æ¨¡å‹å¯ä»¥è¯·æ±‚è°ƒç”¨å·¥å…·ï¼Œæˆ‘ä»¬éœ€è¦ç¼–å†™ä¸€ä¸ªå¯ä»¥å®é™…è°ƒç”¨å·¥å…·çš„å‡½æ•°
è¯¥å·¥å…·ã€‚

è¯¥å‡½æ•°å°†é€šè¿‡åç§°é€‰æ‹©é€‚å½“çš„å·¥å…·ï¼Œå¹¶å°†æ¨¡å‹é€‰æ‹©çš„å‚æ•°ä¼ é€’ç»™å®ƒã€‚


```python
<!--IMPORTS:[{"imported": "RunnableConfig", "source": "langchain_core.runnables", "docs": "https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.config.RunnableConfig.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}]-->
from typing import Any, Dict, Optional, TypedDict

from langchain_core.runnables import RunnableConfig


class ToolCallRequest(TypedDict):
    """A typed dict that shows the inputs into the invoke_tool function."""

    name: str
    arguments: Dict[str, Any]


def invoke_tool(
    tool_call_request: ToolCallRequest, config: Optional[RunnableConfig] = None
):
    """A function that we can use the perform a tool invocation.

    Args:
        tool_call_request: a dict that contains the keys name and arguments.
            The name must match the name of a tool that exists.
            The arguments are the arguments to that tool.
        config: This is configuration information that LangChain uses that contains
            things like callbacks, metadata, etc.See LCEL documentation about RunnableConfig.

    Returns:
        output from the requested tool
    """
    tool_name_to_tool = {tool.name: tool for tool in tools}
    name = tool_call_request["name"]
    requested_tool = tool_name_to_tool[name]
    return requested_tool.invoke(tool_call_request["arguments"], config=config)
```

è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹ ğŸ§ªï¼


```python
invoke_tool({"name": "multiply", "arguments": {"x": 3, "y": 5}})
```



```output
15.0
```


## è®©æˆ‘ä»¬æŠŠå®ƒç»„åˆèµ·æ¥

è®©æˆ‘ä»¬æŠŠå®ƒç»„åˆæˆä¸€ä¸ªå¯ä»¥è¿›è¡ŒåŠ æ³•å’Œä¹˜æ³•è¿ç®—çš„è®¡ç®—å™¨é“¾ã€‚


```python
chain = prompt | model | JsonOutputParser() | invoke_tool
chain.invoke({"input": "what's thirteen times 4.14137281"})
```



```output
53.83784653
```


## è¿”å›å·¥å…·è¾“å…¥

è¿”å›ä¸ä»…æ˜¯å·¥å…·è¾“å‡ºè€Œä¸”æ˜¯å·¥å…·è¾“å…¥æ˜¯å¾ˆæœ‰å¸®åŠ©çš„ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ `RunnablePassthrough.assign` è½»æ¾åšåˆ°è¿™ä¸€ç‚¹ï¼Œå°†å·¥å…·è¾“å‡ºä¼ é€’ã€‚è¿™æ ·ä¼šå°†è¾“å…¥ä¼ é€’ç»™ RunnablePassthrough ç»„ä»¶ï¼ˆå‡è®¾æ˜¯ä¸€ä¸ªå­—å…¸ï¼‰ï¼Œå¹¶åœ¨å…¶ä¸Šæ·»åŠ ä¸€ä¸ªé”®ï¼ŒåŒæ—¶ä»ç„¶ä¼ é€’å½“å‰è¾“å…¥ä¸­çš„æ‰€æœ‰å†…å®¹ï¼š


```python
<!--IMPORTS:[{"imported": "RunnablePassthrough", "source": "langchain_core.runnables", "docs": "https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html", "title": "How to add ad-hoc tool calling capability to LLMs and Chat Models"}]-->
from langchain_core.runnables import RunnablePassthrough

chain = (
    prompt | model | JsonOutputParser() | RunnablePassthrough.assign(output=invoke_tool)
)
chain.invoke({"input": "what's thirteen times 4.14137281"})
```



```output
{'name': 'multiply',
 'arguments': {'x': 13, 'y': 4.14137281},
 'output': 53.83784653}
```


## æ¥ä¸‹æ¥æ˜¯ä»€ä¹ˆï¼Ÿ

æœ¬ä½¿ç”¨æ‰‹å†Œå±•ç¤ºäº†æ¨¡å‹æ­£ç¡®è¾“å‡ºæ‰€æœ‰æ‰€éœ€å·¥å…·ä¿¡æ¯çš„â€œç†æƒ³è·¯å¾„â€ã€‚

å®é™…ä¸Šï¼Œå¦‚æœæ‚¨ä½¿ç”¨æ›´å¤æ‚çš„å·¥å…·ï¼Œæ‚¨å°†å¼€å§‹é‡åˆ°æ¨¡å‹çš„é”™è¯¯ï¼Œç‰¹åˆ«æ˜¯å¯¹äºé‚£äº›æ²¡æœ‰é’ˆå¯¹å·¥å…·è°ƒç”¨è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹å’Œèƒ½åŠ›è¾ƒå¼±çš„æ¨¡å‹ã€‚

æ‚¨éœ€è¦å‡†å¤‡å¥½æ·»åŠ ç­–ç•¥ä»¥æ”¹å–„æ¨¡å‹çš„è¾“å‡ºï¼›ä¾‹å¦‚ï¼Œ

1. æä¾›å°‘é‡ç¤ºä¾‹ã€‚
2. æ·»åŠ é”™è¯¯å¤„ç†ï¼ˆä¾‹å¦‚ï¼Œæ•è·å¼‚å¸¸å¹¶å°†å…¶åé¦ˆç»™å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè¯·æ±‚å…¶çº æ­£ä¹‹å‰çš„è¾“å‡ºï¼‰ã€‚
