---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/how_to/sql_csv.ipynb
---
# å¦‚ä½•åœ¨CSVä¸Šè¿›è¡Œé—®ç­”

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰éå¸¸é€‚åˆæ„å»ºå„ç§æ•°æ®æºä¸Šçš„é—®ç­”ç³»ç»Ÿã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å¦‚ä½•åœ¨å­˜å‚¨åœ¨CSVæ–‡ä»¶ä¸­çš„æ•°æ®ä¸Šæ„å»ºé—®ç­”ç³»ç»Ÿã€‚ä¸ä½¿ç”¨SQLæ•°æ®åº“ä¸€æ ·ï¼Œå¤„ç†CSVæ–‡ä»¶çš„å…³é”®æ˜¯è®©LLMè®¿é—®æŸ¥è¯¢å’Œä¸æ•°æ®äº¤äº’çš„å·¥å…·ã€‚å®ç°è¿™ä¸€ç‚¹çš„ä¸¤ç§ä¸»è¦æ–¹æ³•æ˜¯ï¼š

* **æ¨è**ï¼šå°†CSVæ–‡ä»¶åŠ è½½åˆ°SQLæ•°æ®åº“ä¸­ï¼Œå¹¶ä½¿ç”¨[SQLæ•™ç¨‹](/docs/tutorials/sql_qa)ä¸­æ¦‚è¿°çš„æ–¹æ³•ã€‚
* è®©LLMè®¿é—®ä¸€ä¸ªPythonç¯å¢ƒï¼Œåœ¨å…¶ä¸­å¯ä»¥ä½¿ç”¨åƒPandasè¿™æ ·çš„åº“ä¸æ•°æ®è¿›è¡Œäº¤äº’ã€‚

æˆ‘ä»¬å°†åœ¨æœ¬æŒ‡å—ä¸­æ¶µç›–è¿™ä¸¤ç§æ–¹æ³•ã€‚

## âš ï¸ å®‰å…¨æç¤º âš ï¸

ä¸Šè¿°ä¸¤ç§æ–¹æ³•éƒ½å­˜åœ¨é‡å¤§é£é™©ã€‚ä½¿ç”¨SQLéœ€è¦æ‰§è¡Œæ¨¡å‹ç”Ÿæˆçš„SQLæŸ¥è¯¢ã€‚ä½¿ç”¨åƒPandasè¿™æ ·çš„åº“éœ€è¦è®©æ¨¡å‹æ‰§è¡ŒPythonä»£ç ã€‚ç”±äºä¸¥æ ¼é™åˆ¶SQLè¿æ¥æƒé™å’Œæ¸…ç†SQLæŸ¥è¯¢æ¯”æ²™ç®±åŒ–Pythonç¯å¢ƒæ›´å®¹æ˜“ï¼Œ**æˆ‘ä»¬å¼ºçƒˆå»ºè®®é€šè¿‡SQLä¸CSVæ•°æ®è¿›è¡Œäº¤äº’ã€‚** æœ‰å…³ä¸€èˆ¬å®‰å…¨æœ€ä½³å®è·µçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·[æŸ¥çœ‹è¿™é‡Œ](/docs/security)ã€‚

## è®¾ç½®
æœ¬æŒ‡å—çš„ä¾èµ–é¡¹ï¼š


```python
%pip install -qU langchain langchain-openai langchain-community langchain-experimental pandas
```

è®¾ç½®æ‰€éœ€çš„ç¯å¢ƒå˜é‡ï¼š


```python
# Using LangSmith is recommended but not required. Uncomment below lines to use.
# import os
# os.environ["LANGCHAIN_TRACING_V2"] = "true"
# os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()
```

å¦‚æœæ‚¨è¿˜æ²¡æœ‰ï¼Œè¯·ä¸‹è½½[Titanicæ•°æ®é›†](https://www.kaggle.com/datasets/yasserh/titanic-dataset)ï¼š


```python
!wget https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv -O titanic.csv
```


```python
import pandas as pd

df = pd.read_csv("titanic.csv")
print(df.shape)
print(df.columns.tolist())
```
```output
(887, 8)
['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare']
```
## SQL

ä½¿ç”¨SQLä¸CSVæ•°æ®äº¤äº’æ˜¯æ¨èçš„æ–¹æ³•ï¼Œå› ä¸ºå®ƒæ¯”ä»»æ„Pythonæ›´å®¹æ˜“é™åˆ¶æƒé™å’Œæ¸…ç†æŸ¥è¯¢ã€‚

å¤§å¤šæ•°SQLæ•°æ®åº“éƒ½å¾ˆå®¹æ˜“å°†CSVæ–‡ä»¶åŠ è½½ä¸ºè¡¨ï¼ˆ[DuckDB](https://duckdb.org/docs/data/csv/overview.html)ï¼Œ[SQLite](https://www.sqlite.org/csv.html)ç­‰ï¼‰ã€‚å®Œæˆæ­¤æ“ä½œåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨[SQLæ•™ç¨‹](/docs/tutorials/sql_qa)ä¸­æ¦‚è¿°çš„æ‰€æœ‰é“¾å’Œä»£ç†åˆ›å»ºæŠ€æœ¯ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»¬å¦‚ä½•ä½¿ç”¨SQLiteçš„å¿«é€Ÿç¤ºä¾‹ï¼š


```python
<!--IMPORTS:[{"imported": "SQLDatabase", "source": "langchain_community.utilities", "docs": "https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html", "title": "How to do question answering over CSVs"}]-->
from langchain_community.utilities import SQLDatabase
from sqlalchemy import create_engine

engine = create_engine("sqlite:///titanic.db")
df.to_sql("titanic", engine, index=False)
```



```output
887
```



```python
db = SQLDatabase(engine=engine)
print(db.dialect)
print(db.get_usable_table_names())
print(db.run("SELECT * FROM titanic WHERE Age < 2;"))
```
```output
sqlite
['titanic']
[(1, 2, 'Master. Alden Gates Caldwell', 'male', 0.83, 0, 2, 29.0), (0, 3, 'Master. Eino Viljami Panula', 'male', 1.0, 4, 1, 39.6875), (1, 3, 'Miss. Eleanor Ileen Johnson', 'female', 1.0, 1, 1, 11.1333), (1, 2, 'Master. Richard F Becker', 'male', 1.0, 2, 1, 39.0), (1, 1, 'Master. Hudson Trevor Allison', 'male', 0.92, 1, 2, 151.55), (1, 3, 'Miss. Maria Nakid', 'female', 1.0, 0, 2, 15.7417), (0, 3, 'Master. Sidney Leonard Goodwin', 'male', 1.0, 5, 2, 46.9), (1, 3, 'Miss. Helene Barbara Baclini', 'female', 0.75, 2, 1, 19.2583), (1, 3, 'Miss. Eugenie Baclini', 'female', 0.75, 2, 1, 19.2583), (1, 2, 'Master. Viljo Hamalainen', 'male', 0.67, 1, 1, 14.5), (1, 3, 'Master. Bertram Vere Dean', 'male', 1.0, 1, 2, 20.575), (1, 3, 'Master. Assad Alexander Thomas', 'male', 0.42, 0, 1, 8.5167), (1, 2, 'Master. Andre Mallet', 'male', 1.0, 0, 2, 37.0042), (1, 2, 'Master. George Sibley Richards', 'male', 0.83, 1, 1, 18.75)]
```
å¹¶åˆ›å»ºä¸€ä¸ª[SQLä»£ç†](/docs/tutorials/sql_qa)ä¸ä¹‹äº¤äº’ï¼š

import ChatModelTabs from "@theme/ChatModelTabs";

<ChatModelTabs customVarName="llm" />



```python
<!--IMPORTS:[{"imported": "create_sql_agent", "source": "langchain_community.agent_toolkits", "docs": "https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.sql.base.create_sql_agent.html", "title": "How to do question answering over CSVs"}]-->
from langchain_community.agent_toolkits import create_sql_agent

agent_executor = create_sql_agent(llm, db=db, agent_type="openai-tools", verbose=True)
```


```python
agent_executor.invoke({"input": "what's the average age of survivors"})
```
```output


[1m> Entering new SQL Agent Executor chain...[0m
[32;1m[1;3m
Invoking: `sql_db_list_tables` with `{}`


[0m[38;5;200m[1;3mtitanic[0m[32;1m[1;3m
Invoking: `sql_db_schema` with `{'table_names': 'titanic'}`


[0m[33;1m[1;3m
CREATE TABLE titanic (
	"Survived" BIGINT, 
	"Pclass" BIGINT, 
	"Name" TEXT, 
	"Sex" TEXT, 
	"Age" FLOAT, 
	"Siblings/Spouses Aboard" BIGINT, 
	"Parents/Children Aboard" BIGINT, 
	"Fare" FLOAT
)

/*
3 rows from titanic table:
Survived	Pclass	Name	Sex	Age	Siblings/Spouses Aboard	Parents/Children Aboard	Fare
0	3	Mr. Owen Harris Braund	male	22.0	1	0	7.25
1	1	Mrs. John Bradley (Florence Briggs Thayer) Cumings	female	38.0	1	0	71.2833
1	3	Miss. Laina Heikkinen	female	26.0	0	0	7.925
*/[0m[32;1m[1;3m
Invoking: `sql_db_query` with `{'query': 'SELECT AVG(Age) AS Average_Age FROM titanic WHERE Survived = 1'}`


[0m[36;1m[1;3m[(28.408391812865496,)][0m[32;1m[1;3mThe average age of survivors in the Titanic dataset is approximately 28.41 years.[0m

[1m> Finished chain.[0m
```


```output
{'input': "what's the average age of survivors",
 'output': 'The average age of survivors in the Titanic dataset is approximately 28.41 years.'}
```


è¿™ç§æ–¹æ³•å¾ˆå®¹æ˜“æ¨å¹¿åˆ°å¤šä¸ªCSVï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥å°†æ¯ä¸ªCSVåŠ è½½åˆ°æ•°æ®åº“ä¸­ä½œä¸ºè‡ªå·±çš„è¡¨ã€‚è¯·å‚è§ä¸‹é¢çš„[å¤šä¸ªCSV](/docs/how_to/sql_csv#multiple-csvs)éƒ¨åˆ†ã€‚

## Pandas

é™¤äº†SQLï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨æ•°æ®åˆ†æåº“å¦‚pandaså’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç ç”Ÿæˆèƒ½åŠ›ä¸CSVæ•°æ®äº¤äº’ã€‚åŒæ ·ï¼Œ**é™¤éæ‚¨æœ‰å¹¿æ³›çš„å®‰å…¨æªæ–½ï¼Œå¦åˆ™è¿™ç§æ–¹æ³•ä¸é€‚åˆç”Ÿäº§ç”¨ä¾‹**ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„ä»£ç æ‰§è¡Œå·¥å…·å’Œæ„é€ å‡½æ•°ä½äº`langchain-experimental`åŒ…ä¸­ã€‚

### Chain

å¤§å¤šæ•°å¤§å‹è¯­è¨€æ¨¡å‹å·²ç»åœ¨è¶³å¤Ÿçš„ pandas Python ä»£ç ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œå› æ­¤å®ƒä»¬å¯ä»¥ä»…é€šè¿‡è¯·æ±‚ç”Ÿæˆä»£ç ï¼š


```python
ai_msg = llm.invoke(
    "I have a pandas DataFrame 'df' with columns 'Age' and 'Fare'. Write code to compute the correlation between the two columns. Return Markdown for a Python code snippet and nothing else."
)
print(ai_msg.content)
```
```output
\`\`\`python
correlation = df['Age'].corr(df['Fare'])
correlation
\`\`\`
```
æˆ‘ä»¬å¯ä»¥å°†è¿™ç§èƒ½åŠ›ä¸ä¸€ä¸ªæ‰§è¡Œ Python çš„å·¥å…·ç»“åˆèµ·æ¥ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æ•°æ®åˆ†æé“¾ã€‚æˆ‘ä»¬é¦–å…ˆæƒ³å°†æˆ‘ä»¬çš„ CSV è¡¨åŠ è½½ä¸ºæ•°æ®æ¡†ï¼Œå¹¶è®©å·¥å…·è®¿é—®è¿™ä¸ªæ•°æ®æ¡†ï¼š


```python
<!--IMPORTS:[{"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to do question answering over CSVs"}, {"imported": "PythonAstREPLTool", "source": "langchain_experimental.tools", "docs": "https://python.langchain.com/api_reference/experimental/tools/langchain_experimental.tools.python.tool.PythonAstREPLTool.html", "title": "How to do question answering over CSVs"}]-->
import pandas as pd
from langchain_core.prompts import ChatPromptTemplate
from langchain_experimental.tools import PythonAstREPLTool

df = pd.read_csv("titanic.csv")
tool = PythonAstREPLTool(locals={"df": df})
tool.invoke("df['Fare'].mean()")
```



```output
32.30542018038331
```


ä¸ºäº†å¸®åŠ©ç¡®ä¿æˆ‘ä»¬æ­£ç¡®ä½¿ç”¨ Python å·¥å…·ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [å·¥å…·è°ƒç”¨](/docs/how_to/tool_calling)ï¼š


```python
llm_with_tools = llm.bind_tools([tool], tool_choice=tool.name)
response = llm_with_tools.invoke(
    "I have a dataframe 'df' and want to know the correlation between the 'Age' and 'Fare' columns"
)
response
```



```output
AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_SBrK246yUbdnJemXFC8Iod05', 'function': {'arguments': '{"query":"df.corr()[\'Age\'][\'Fare\']"}', 'name': 'python_repl_ast'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 125, 'total_tokens': 138}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None}, id='run-1fd332ba-fa72-4351-8182-d464e7368311-0', tool_calls=[{'name': 'python_repl_ast', 'args': {'query': "df.corr()['Age']['Fare']"}, 'id': 'call_SBrK246yUbdnJemXFC8Iod05'}])
```



```python
response.tool_calls
```



```output
[{'name': 'python_repl_ast',
  'args': {'query': "df.corr()['Age']['Fare']"},
  'id': 'call_SBrK246yUbdnJemXFC8Iod05'}]
```


æˆ‘ä»¬å°†æ·»åŠ ä¸€ä¸ªå·¥å…·è¾“å‡ºè§£æå™¨ï¼Œä»¥å°†å‡½æ•°è°ƒç”¨æå–ä¸ºå­—å…¸ï¼š


```python
<!--IMPORTS:[{"imported": "JsonOutputKeyToolsParser", "source": "langchain_core.output_parsers.openai_tools", "docs": "https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.JsonOutputKeyToolsParser.html", "title": "How to do question answering over CSVs"}]-->
from langchain_core.output_parsers.openai_tools import JsonOutputKeyToolsParser

parser = JsonOutputKeyToolsParser(key_name=tool.name, first_tool_only=True)
(llm_with_tools | parser).invoke(
    "I have a dataframe 'df' and want to know the correlation between the 'Age' and 'Fare' columns"
)
```



```output
{'query': "df[['Age', 'Fare']].corr()"}
```


å¹¶ç»“åˆä¸€ä¸ªæç¤ºï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥ä»…æŒ‡å®šä¸€ä¸ªé—®é¢˜ï¼Œè€Œæ— éœ€åœ¨æ¯æ¬¡è°ƒç”¨æ—¶æŒ‡å®šæ•°æ®æ¡†ä¿¡æ¯ï¼š


```python
system = f"""You have access to a pandas dataframe `df`. \
Here is the output of `df.head().to_markdown()`:

\`\`\`
{df.head().to_markdown()}
\`\`\`

Given a user question, write the Python code to answer it. \
Return ONLY the valid Python code and nothing else. \
Don't assume you have access to any libraries other than built-in Python ones and pandas."""
prompt = ChatPromptTemplate.from_messages([("system", system), ("human", "{question}")])
code_chain = prompt | llm_with_tools | parser
code_chain.invoke({"question": "What's the correlation between age and fare"})
```



```output
{'query': "df[['Age', 'Fare']].corr()"}
```


æœ€åï¼Œæˆ‘ä»¬å°†æ·»åŠ æˆ‘ä»¬çš„ Python å·¥å…·ï¼Œä»¥ä¾¿ç”Ÿæˆçš„ä»£ç å®é™…ä¸Šè¢«æ‰§è¡Œï¼š


```python
chain = prompt | llm_with_tools | parser | tool
chain.invoke({"question": "What's the correlation between age and fare"})
```



```output
0.11232863699941621
```


å°±è¿™æ ·ï¼Œæˆ‘ä»¬æœ‰äº†ä¸€ä¸ªç®€å•çš„æ•°æ®åˆ†æé“¾ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æŸ¥çœ‹ LangSmith è·Ÿè¸ªæ¥äº†è§£ä¸­é—´æ­¥éª¤ï¼šhttps://smith.langchain.com/public/b1309290-7212-49b7-bde2-75b39a32b49a/r

æˆ‘ä»¬å¯ä»¥åœ¨æœ€åæ·»åŠ ä¸€ä¸ªé¢å¤–çš„ LLM è°ƒç”¨ï¼Œä»¥ç”Ÿæˆå¯¹è¯å“åº”ï¼Œè¿™æ ·æˆ‘ä»¬å°±ä¸ä»…ä»…æ˜¯ç”¨å·¥å…·è¾“å‡ºè¿›è¡Œå“åº”ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æƒ³åœ¨æç¤ºä¸­æ·»åŠ ä¸€ä¸ªèŠå¤©å†å² `MessagesPlaceholder`ï¼š


```python
<!--IMPORTS:[{"imported": "ToolMessage", "source": "langchain_core.messages", "docs": "https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html", "title": "How to do question answering over CSVs"}, {"imported": "StrOutputParser", "source": "langchain_core.output_parsers", "docs": "https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html", "title": "How to do question answering over CSVs"}, {"imported": "MessagesPlaceholder", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.MessagesPlaceholder.html", "title": "How to do question answering over CSVs"}, {"imported": "RunnablePassthrough", "source": "langchain_core.runnables", "docs": "https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html", "title": "How to do question answering over CSVs"}]-->
from operator import itemgetter

from langchain_core.messages import ToolMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough

system = f"""You have access to a pandas dataframe `df`. \
Here is the output of `df.head().to_markdown()`:

\`\`\`
{df.head().to_markdown()}
\`\`\`

Given a user question, write the Python code to answer it. \
Don't assume you have access to any libraries other than built-in Python ones and pandas.
Respond directly to the question once you have enough information to answer it."""
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            system,
        ),
        ("human", "{question}"),
        # This MessagesPlaceholder allows us to optionally append an arbitrary number of messages
        # at the end of the prompt using the 'chat_history' arg.
        MessagesPlaceholder("chat_history", optional=True),
    ]
)


def _get_chat_history(x: dict) -> list:
    """Parse the chain output up to this point into a list of chat history messages to insert in the prompt."""
    ai_msg = x["ai_msg"]
    tool_call_id = x["ai_msg"].additional_kwargs["tool_calls"][0]["id"]
    tool_msg = ToolMessage(tool_call_id=tool_call_id, content=str(x["tool_output"]))
    return [ai_msg, tool_msg]


chain = (
    RunnablePassthrough.assign(ai_msg=prompt | llm_with_tools)
    .assign(tool_output=itemgetter("ai_msg") | parser | tool)
    .assign(chat_history=_get_chat_history)
    .assign(response=prompt | llm | StrOutputParser())
    .pick(["tool_output", "response"])
)
```


```python
chain.invoke({"question": "What's the correlation between age and fare"})
```



```output
{'tool_output': 0.11232863699941616,
 'response': 'The correlation between age and fare is approximately 0.1123.'}
```


è¿™æ˜¯æ­¤è¿è¡Œçš„ LangSmith è·Ÿè¸ªï¼šhttps://smith.langchain.com/public/14e38d70-45b1-4b81-8477-9fd2b7c07ea6/r

### ä»£ç†

å¯¹äºå¤æ‚çš„é—®é¢˜ï¼ŒLLMèƒ½å¤Ÿåœ¨ä¿æŒä¹‹å‰æ‰§è¡Œçš„è¾“å…¥å’Œè¾“å‡ºçš„åŒæ—¶ï¼Œè¿­ä»£æ‰§è¡Œä»£ç æ˜¯éå¸¸æœ‰å¸®åŠ©çš„ã€‚è¿™å°±æ˜¯ä»£ç†çš„ä½œç”¨ã€‚å®ƒä»¬å…è®¸LLMå†³å®šå·¥å…·éœ€è¦è¢«è°ƒç”¨å¤šå°‘æ¬¡ï¼Œå¹¶è·Ÿè¸ªåˆ°ç›®å‰ä¸ºæ­¢å®ƒæ‰€åšçš„æ‰§è¡Œã€‚[create_pandas_dataframe_agent](https://python.langchain.com/api_reference/experimental/agents/langchain_experimental.agents.agent_toolkits.pandas.base.create_pandas_dataframe_agent.html)æ˜¯ä¸€ä¸ªå†…ç½®ä»£ç†ï¼Œä½¿å¾—å¤„ç†æ•°æ®æ¡†å˜å¾—ç®€å•ï¼š


```python
<!--IMPORTS:[{"imported": "create_pandas_dataframe_agent", "source": "langchain_experimental.agents", "docs": "https://python.langchain.com/api_reference/experimental/agents/langchain_experimental.agents.agent_toolkits.pandas.base.create_pandas_dataframe_agent.html", "title": "How to do question answering over CSVs"}]-->
from langchain_experimental.agents import create_pandas_dataframe_agent

agent = create_pandas_dataframe_agent(llm, df, agent_type="openai-tools", verbose=True)
agent.invoke(
    {
        "input": "What's the correlation between age and fare? is that greater than the correlation between fare and survival?"
    }
)
```
```output


[1m> Entering new AgentExecutor chain...[0m
[32;1m[1;3m
Invoking: `python_repl_ast` with `{'query': "df[['Age', 'Fare']].corr().iloc[0,1]"}`


[0m[36;1m[1;3m0.11232863699941621[0m[32;1m[1;3m
Invoking: `python_repl_ast` with `{'query': "df[['Fare', 'Survived']].corr().iloc[0,1]"}`


[0m[36;1m[1;3m0.2561785496289603[0m[32;1m[1;3mThe correlation between Age and Fare is approximately 0.112, and the correlation between Fare and Survival is approximately 0.256.

Therefore, the correlation between Fare and Survival (0.256) is greater than the correlation between Age and Fare (0.112).[0m

[1m> Finished chain.[0m
```


```output
{'input': "What's the correlation between age and fare? is that greater than the correlation between fare and survival?",
 'output': 'The correlation between Age and Fare is approximately 0.112, and the correlation between Fare and Survival is approximately 0.256.\n\nTherefore, the correlation between Fare and Survival (0.256) is greater than the correlation between Age and Fare (0.112).'}
```


è¿™æ˜¯æ­¤æ¬¡è¿è¡Œçš„LangSmithè¿½è¸ªè®°å½•ï¼šhttps://smith.langchain.com/public/6a86aee2-4f22-474a-9264-bd4c7283e665/r

### å¤šä¸ªCSVæ–‡ä»¶ {#multiple-csvs}

è¦å¤„ç†å¤šä¸ªCSVæ–‡ä»¶ï¼ˆæˆ–æ•°æ®æ¡†ï¼‰ï¼Œæˆ‘ä»¬åªéœ€å°†å¤šä¸ªæ•°æ®æ¡†ä¼ é€’ç»™æˆ‘ä»¬çš„Pythonå·¥å…·ã€‚æˆ‘ä»¬çš„`create_pandas_dataframe_agent`æ„é€ å‡½æ•°å¯ä»¥å¼€ç®±å³ç”¨åœ°åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥ä¼ å…¥ä¸€ä¸ªæ•°æ®æ¡†åˆ—è¡¨ï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸€ä¸ªã€‚å¦‚æœæˆ‘ä»¬è‡ªå·±æ„å»ºé“¾ï¼Œå¯ä»¥è¿™æ ·åšï¼š


```python
df_1 = df[["Age", "Fare"]]
df_2 = df[["Fare", "Survived"]]

tool = PythonAstREPLTool(locals={"df_1": df_1, "df_2": df_2})
llm_with_tool = llm.bind_tools(tools=[tool], tool_choice=tool.name)
df_template = """\`\`\`python
{df_name}.head().to_markdown()
>>> {df_head}
\`\`\`"""
df_context = "\n\n".join(
    df_template.format(df_head=_df.head().to_markdown(), df_name=df_name)
    for _df, df_name in [(df_1, "df_1"), (df_2, "df_2")]
)

system = f"""You have access to a number of pandas dataframes. \
Here is a sample of rows from each dataframe and the python code that was used to generate the sample:

{df_context}

Given a user question about the dataframes, write the Python code to answer it. \
Don't assume you have access to any libraries other than built-in Python ones and pandas. \
Make sure to refer only to the variables mentioned above."""
prompt = ChatPromptTemplate.from_messages([("system", system), ("human", "{question}")])

chain = prompt | llm_with_tool | parser | tool
chain.invoke(
    {
        "question": "return the difference in the correlation between age and fare and the correlation between fare and survival"
    }
)
```



```output
0.14384991262954416
```


è¿™æ˜¯æ­¤æ¬¡è¿è¡Œçš„LangSmithè¿½è¸ªè®°å½•ï¼šhttps://smith.langchain.com/public/cc2a7d7f-7c5a-4e77-a10c-7b5420fcd07f/r

### æ²™ç›’ä»£ç æ‰§è¡Œ

æœ‰è®¸å¤šå·¥å…·ï¼Œå¦‚[E2B](/docs/integrations/tools/e2b_data_analysis)å’Œ[Bearly](/docs/integrations/tools/bearly)ï¼Œæä¾›Pythonä»£ç æ‰§è¡Œçš„æ²™ç›’ç¯å¢ƒï¼Œä»¥ä¾¿äºæ›´å®‰å…¨çš„ä»£ç æ‰§è¡Œé“¾å’Œä»£ç†ã€‚

## ä¸‹ä¸€æ­¥

å¯¹äºæ›´é«˜çº§çš„æ•°æ®åˆ†æåº”ç”¨ï¼Œæˆ‘ä»¬å»ºè®®æŸ¥çœ‹ï¼š

* [SQLæ•™ç¨‹](/docs/tutorials/sql_qa)ï¼šå¤„ç†SQLæ•°æ®åº“å’ŒCSVæ–‡ä»¶çš„è®¸å¤šæŒ‘æˆ˜å¯¹äºä»»ä½•ç»“æ„åŒ–æ•°æ®ç±»å‹éƒ½æ˜¯é€šç”¨çš„ï¼Œå› æ­¤å³ä½¿æ‚¨ä½¿ç”¨Pandasè¿›è¡ŒCSVæ•°æ®åˆ†æï¼Œé˜…è¯»SQLæŠ€æœ¯ä¹Ÿæ˜¯æœ‰ç”¨çš„ã€‚
* [å·¥å…·ä½¿ç”¨](/docs/how_to/tool_calling): å…³äºåœ¨ä½¿ç”¨è°ƒç”¨å·¥å…·çš„é“¾å’Œä»£ç†æ—¶çš„ä¸€èˆ¬æœ€ä½³å®è·µçš„æŒ‡å—
* [ä»£ç†](/docs/tutorials/agents): ç†è§£æ„å»ºå¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†çš„åŸºæœ¬åŸç†ã€‚
* é›†æˆ: åƒ [E2B](/docs/integrations/tools/e2b_data_analysis) å’Œ [Bearly](/docs/integrations/tools/bearly) çš„æ²™ç›’ç¯å¢ƒï¼Œåƒ [SQLDatabase](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html#langchain_community.utilities.sql_database.SQLDatabase) çš„å®ç”¨å·¥å…·ï¼Œç›¸å…³ä»£ç†å¦‚ [Spark DataFrame ä»£ç†](/docs/integrations/tools/spark_sql)ã€‚
