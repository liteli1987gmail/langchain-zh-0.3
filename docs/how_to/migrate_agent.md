---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/how_to/migrate_agent.ipynb
keywords: [create_react_agent, create_react_agent()]
---
# å¦‚ä½•ä»é—ç•™çš„ LangChain ä»£ç†è¿ç§»åˆ° LangGraph

:::info Prerequisites

æœ¬æŒ‡å—å‡è®¾æ‚¨ç†Ÿæ‚‰ä»¥ä¸‹æ¦‚å¿µï¼š
- [ä»£ç†](/docs/concepts/#agents)
- [LangGraph](https://langchain-ai.github.io/langgraph/)
- [å·¥å…·è°ƒç”¨](/docs/how_to/tool_calling/)

:::

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é‡ç‚¹ä»‹ç»å¦‚ä½•ä»é—ç•™çš„ LangChain ä»£ç†è¿ç§»åˆ°æ›´çµæ´»çš„ [LangGraph](https://langchain-ai.github.io/langgraph/) ä»£ç†ã€‚
LangChain ä»£ç†ï¼ˆç‰¹åˆ«æ˜¯ [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor)ï¼‰å…·æœ‰å¤šä¸ªé…ç½®å‚æ•°ã€‚
åœ¨è¿™ä¸ªç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºè¿™äº›å‚æ•°å¦‚ä½•æ˜ å°„åˆ° LangGraph ååº”ä»£ç†æ‰§è¡Œå™¨ï¼Œä½¿ç”¨ [create_react_agent](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent) é¢„æ„å»ºåŠ©æ‰‹æ–¹æ³•ã€‚

#### å…ˆå†³æ¡ä»¶

æœ¬ä½¿ç”¨æŒ‡å—ä½¿ç”¨ OpenAI ä½œä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ã€‚å®‰è£…ä¾èµ–é¡¹ä»¥è¿è¡Œã€‚


```python
%%capture --no-stderr
%pip install -U langgraph langchain langchain-openai
```

ç„¶åï¼Œè®¾ç½®æ‚¨çš„ OpenAI API å¯†é’¥ã€‚


```python
import getpass
import os

if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API key:\n")
```

## åŸºæœ¬ç”¨æ³•

å¯¹äºå·¥å…·è°ƒç”¨çš„ ReAct é£æ ¼ä»£ç†çš„åŸºæœ¬åˆ›å»ºå’Œä½¿ç”¨ï¼ŒåŠŸèƒ½æ˜¯ç›¸åŒçš„ã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªæ¨¡å‹å’Œå·¥å…·ï¼Œç„¶åæˆ‘ä»¬å°†ä½¿ç”¨è¿™äº›æ¥åˆ›å»ºä¸€ä¸ªä»£ç†ã€‚


```python
<!--IMPORTS:[{"imported": "tool", "source": "langchain_core.tools", "docs": "https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}]-->
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o")


@tool
def magic_function(input: int) -> int:
    """Applies a magic function to an input."""
    return input + 2


tools = [magic_function]


query = "what is the value of magic_function(3)?"
```

å¯¹äº LangChain [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor)ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå¸¦æœ‰ä»£ç†ä¸´æ—¶è®°äº‹æœ¬å ä½ç¬¦çš„æç¤ºã€‚ä»£ç†å¯ä»¥å¦‚ä¸‹è°ƒç”¨ï¼š


```python
<!--IMPORTS:[{"imported": "AgentExecutor", "source": "langchain.agents", "docs": "https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "create_tool_calling_agent", "source": "langchain.agents", "docs": "https://python.langchain.com/api_reference/langchain/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}]-->
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant"),
        ("human", "{input}"),
        # Placeholders fill up a **list** of messages
        ("placeholder", "{agent_scratchpad}"),
    ]
)


agent = create_tool_calling_agent(model, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools)

agent_executor.invoke({"input": query})
```



```output
{'input': 'what is the value of magic_function(3)?',
 'output': 'The value of `magic_function(3)` is 5.'}
```


LangGraph çš„ [react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent) ç®¡ç†ä¸€ä¸ªç”±æ¶ˆæ¯åˆ—è¡¨å®šä¹‰çš„çŠ¶æ€ã€‚å®ƒå°†ç»§ç»­å¤„ç†è¯¥åˆ—è¡¨ï¼Œç›´åˆ°ä»£ç†çš„è¾“å‡ºä¸­æ²¡æœ‰å·¥å…·è°ƒç”¨ã€‚è¦å¯åŠ¨å®ƒï¼Œæˆ‘ä»¬è¾“å…¥ä¸€ç³»åˆ—æ¶ˆæ¯ã€‚è¾“å‡ºå°†åŒ…å«å›¾çš„æ•´ä¸ªçŠ¶æ€â€”â€”åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ˜¯å¯¹è¯å†å²ã€‚




```python
from langgraph.prebuilt import create_react_agent

app = create_react_agent(model, tools)


messages = app.invoke({"messages": [("human", query)]})
{
    "input": query,
    "output": messages["messages"][-1].content,
}
```



```output
{'input': 'what is the value of magic_function(3)?',
 'output': 'The value of `magic_function(3)` is 5.'}
```



```python
message_history = messages["messages"]

new_query = "Pardon?"

messages = app.invoke({"messages": message_history + [("human", new_query)]})
{
    "input": new_query,
    "output": messages["messages"][-1].content,
}
```



```output
{'input': 'Pardon?',
 'output': 'The value returned by `magic_function` when the input is 3 is 5.'}
```


## æç¤ºè¯æ¨¡æ¿

ä½¿ç”¨ä¼ ç»Ÿçš„ LangChain ä»£ç†ï¼Œæ‚¨å¿…é¡»ä¼ å…¥ä¸€ä¸ªæç¤ºè¯æ¨¡æ¿ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å®ƒæ¥æ§åˆ¶ä»£ç†ã€‚

ä½¿ç”¨ LangGraph [react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent)ï¼Œé»˜è®¤æƒ…å†µä¸‹æ²¡æœ‰æç¤ºã€‚æ‚¨å¯ä»¥é€šè¿‡å‡ ç§æ–¹å¼å®ç°å¯¹ä»£ç†çš„ç±»ä¼¼æ§åˆ¶ï¼š

1. å°†ç³»ç»Ÿæ¶ˆæ¯ä½œä¸ºè¾“å…¥ä¼ å…¥
2. ç”¨ç³»ç»Ÿæ¶ˆæ¯åˆå§‹åŒ–ä»£ç†
3. ä½¿ç”¨ä¸€ä¸ªå‡½æ•°åˆå§‹åŒ–ä»£ç†ï¼Œä»¥åœ¨ä¼ é€’ç»™æ¨¡å‹ä¹‹å‰è½¬æ¢æ¶ˆæ¯ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹ä¸‹é¢çš„æ‰€æœ‰å†…å®¹ã€‚æˆ‘ä»¬å°†ä¼ å…¥è‡ªå®šä¹‰æŒ‡ä»¤ï¼Œè®©ä»£ç†ç”¨è¥¿ç­ç‰™è¯­å›åº”ã€‚

é¦–å…ˆï¼Œä½¿ç”¨ `AgentExecutor`ï¼š


```python
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant. Respond only in Spanish."),
        ("human", "{input}"),
        # Placeholders fill up a **list** of messages
        ("placeholder", "{agent_scratchpad}"),
    ]
)


agent = create_tool_calling_agent(model, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools)

agent_executor.invoke({"input": query})
```



```output
{'input': 'what is the value of magic_function(3)?',
 'output': 'El valor de `magic_function(3)` es 5.'}
```


ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä¼ é€’ä¸€ä¸ªè‡ªå®šä¹‰ç³»ç»Ÿæ¶ˆæ¯ç»™ [react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent)ã€‚

LangGraph çš„é¢„æ„å»º `create_react_agent` å¹¶ä¸ç›´æ¥å°†æç¤ºæ¨¡æ¿ä½œä¸ºå‚æ•°ï¼Œè€Œæ˜¯æ¥å—ä¸€ä¸ª [`state_modifier`](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent) å‚æ•°ã€‚è¿™ä¸ªå‚æ•°åœ¨è°ƒç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä¹‹å‰ä¿®æ”¹å›¾çš„çŠ¶æ€ï¼Œå¯ä»¥æ˜¯ä»¥ä¸‹å››ä¸ªå€¼ä¹‹ä¸€ï¼š

- ä¸€ä¸ª `SystemMessage`ï¼Œå®ƒä¼šè¢«æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨çš„å¼€å¤´ã€‚
- ä¸€ä¸ª `string`ï¼Œå®ƒä¼šè¢«è½¬æ¢ä¸º `SystemMessage` å¹¶æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨çš„å¼€å¤´ã€‚
- ä¸€ä¸ª `Callable`ï¼Œå®ƒåº”è¯¥æ¥å—å®Œæ•´çš„å›¾çŠ¶æ€ã€‚è¾“å‡ºå°†ä¼ é€’ç»™è¯­è¨€æ¨¡å‹ã€‚
- æˆ–è€…ä¸€ä¸ª [`Runnable`](/docs/concepts/#langchain-expression-language-lcel)ï¼Œå®ƒåº”è¯¥æ¥å—å®Œæ•´çš„å›¾çŠ¶æ€ã€‚è¾“å‡ºå°†ä¼ é€’ç»™è¯­è¨€æ¨¡å‹ã€‚

è¿™å°±æ˜¯å®ƒåœ¨å®é™…ä¸­çš„æ ·å­ï¼š


```python
<!--IMPORTS:[{"imported": "SystemMessage", "source": "langchain_core.messages", "docs": "https://python.langchain.com/api_reference/core/messages/langchain_core.messages.system.SystemMessage.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}]-->
from langchain_core.messages import SystemMessage
from langgraph.prebuilt import create_react_agent

system_message = "You are a helpful assistant. Respond only in Spanish."
# This could also be a SystemMessage object
# system_message = SystemMessage(content="You are a helpful assistant. Respond only in Spanish.")

app = create_react_agent(model, tools, state_modifier=system_message)


messages = app.invoke({"messages": [("user", query)]})
```

æˆ‘ä»¬è¿˜å¯ä»¥ä¼ å…¥ä¸€ä¸ªä»»æ„å‡½æ•°ã€‚è¿™ä¸ªå‡½æ•°åº”è¯¥æ¥æ”¶ä¸€ç»„æ¶ˆæ¯å¹¶è¾“å‡ºä¸€ç»„æ¶ˆæ¯ã€‚
æˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œå¯¹æ¶ˆæ¯è¿›è¡Œå„ç§ä»»æ„æ ¼å¼åŒ–ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè®©æˆ‘ä»¬åœ¨æ¶ˆæ¯åˆ—è¡¨çš„å¼€å¤´æ·»åŠ ä¸€ä¸ªç³»ç»Ÿæ¶ˆæ¯ã€‚


```python
from langgraph.prebuilt import create_react_agent
from langgraph.prebuilt.chat_agent_executor import AgentState

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant. Respond only in Spanish."),
        ("placeholder", "{messages}"),
    ]
)


def _modify_state_messages(state: AgentState):
    return prompt.invoke({"messages": state["messages"]}).to_messages() + [
        ("user", "Also say 'Pandamonium!' after the answer.")
    ]


app = create_react_agent(model, tools, state_modifier=_modify_state_messages)


messages = app.invoke({"messages": [("human", query)]})
print(
    {
        "input": query,
        "output": messages["messages"][-1].content,
    }
)
```
```output
{'input': 'what is the value of magic_function(3)?', 'output': 'The value of magic_function(3) is 5. Â¡Pandamonium!'}
```
## å†…å­˜

### åœ¨ LangChain ä¸­

ä½¿ç”¨ LangChain çš„ [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter)ï¼Œæ‚¨å¯ä»¥æ·»åŠ èŠå¤© [å†…å­˜](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.memory)ï¼Œä»¥ä¾¿å®ƒå¯ä»¥è¿›è¡Œå¤šè½®å¯¹è¯ã€‚


```python
<!--IMPORTS:[{"imported": "AgentExecutor", "source": "langchain.agents", "docs": "https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "create_tool_calling_agent", "source": "langchain.agents", "docs": "https://python.langchain.com/api_reference/langchain/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "InMemoryChatMessageHistory", "source": "langchain_core.chat_history", "docs": "https://python.langchain.com/api_reference/core/chat_history/langchain_core.chat_history.InMemoryChatMessageHistory.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "RunnableWithMessageHistory", "source": "langchain_core.runnables.history", "docs": "https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "tool", "source": "langchain_core.tools", "docs": "https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}]-->
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o")
memory = InMemoryChatMessageHistory(session_id="test-session")
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant."),
        # First put the history
        ("placeholder", "{chat_history}"),
        # Then the new input
        ("human", "{input}"),
        # Finally the scratchpad
        ("placeholder", "{agent_scratchpad}"),
    ]
)


@tool
def magic_function(input: int) -> int:
    """Applies a magic function to an input."""
    return input + 2


tools = [magic_function]


agent = create_tool_calling_agent(model, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools)

agent_with_chat_history = RunnableWithMessageHistory(
    agent_executor,
    # This is needed because in most real world scenarios, a session id is needed
    # It isn't really used here because we are using a simple in memory ChatMessageHistory
    lambda session_id: memory,
    input_messages_key="input",
    history_messages_key="chat_history",
)

config = {"configurable": {"session_id": "test-session"}}
print(
    agent_with_chat_history.invoke(
        {"input": "Hi, I'm polly! What's the output of magic_function of 3?"}, config
    )["output"]
)
print("---")
print(agent_with_chat_history.invoke({"input": "Remember my name?"}, config)["output"])
print("---")
print(
    agent_with_chat_history.invoke({"input": "what was that output again?"}, config)[
        "output"
    ]
)
```
```output
Hi Polly! The output of applying the magic function to the input 3 is 5.
---
Yes, you mentioned your name is Polly.
---
The output of applying the magic function to the input 3 is 5.
```
### åœ¨ LangGraph ä¸­

å†…å­˜åªæ˜¯ [æŒä¹…æ€§](https://langchain-ai.github.io/langgraph/how-tos/persistence/)ï¼Œä¹Ÿç§°ä¸º [æ£€æŸ¥ç‚¹](https://langchain-ai.github.io/langgraph/reference/checkpoints/)ã€‚

å‘ä»£ç†æ·»åŠ ä¸€ä¸ª `checkpointer`ï¼Œæ‚¨å°†å…è´¹è·å¾—èŠå¤©å†…å­˜ã€‚


```python
from langgraph.checkpoint.memory import MemorySaver  # an in-memory checkpointer
from langgraph.prebuilt import create_react_agent

system_message = "You are a helpful assistant."
# This could also be a SystemMessage object
# system_message = SystemMessage(content="You are a helpful assistant. Respond only in Spanish.")

memory = MemorySaver()
app = create_react_agent(
    model, tools, state_modifier=system_message, checkpointer=memory
)

config = {"configurable": {"thread_id": "test-thread"}}
print(
    app.invoke(
        {
            "messages": [
                ("user", "Hi, I'm polly! What's the output of magic_function of 3?")
            ]
        },
        config,
    )["messages"][-1].content
)
print("---")
print(
    app.invoke({"messages": [("user", "Remember my name?")]}, config)["messages"][
        -1
    ].content
)
print("---")
print(
    app.invoke({"messages": [("user", "what was that output again?")]}, config)[
        "messages"
    ][-1].content
)
```
```output
Hi Polly! The output of applying the magic function to the input 3 is 5.
---
Yes, your name is Polly!
---
The output of applying the magic function to the input 3 was 5.
```
## è¿­ä»£æ­¥éª¤

### åœ¨ LangChain ä¸­

ä½¿ç”¨ LangChain çš„ [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter)ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ [stream](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream)ï¼ˆæˆ–å¼‚æ­¥ `astream`ï¼‰æ–¹æ³•æˆ– [iter](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter) æ–¹æ³•è¿­ä»£æ­¥éª¤ã€‚LangGraph æ”¯æŒä½¿ç”¨ [stream](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream) é€æ­¥è¿­ä»£ã€‚


```python
<!--IMPORTS:[{"imported": "AgentExecutor", "source": "langchain.agents", "docs": "https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "create_tool_calling_agent", "source": "langchain.agents", "docs": "https://python.langchain.com/api_reference/langchain/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "tool", "source": "langchain_core.tools", "docs": "https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}]-->
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o")


prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant."),
        ("human", "{input}"),
        # Placeholders fill up a **list** of messages
        ("placeholder", "{agent_scratchpad}"),
    ]
)


@tool
def magic_function(input: int) -> int:
    """Applies a magic function to an input."""
    return input + 2


tools = [magic_function]

agent = create_tool_calling_agent(model, tools, prompt=prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools)

for step in agent_executor.stream({"input": query}):
    print(step)
```
```output
{'actions': [ToolAgentAction(tool='magic_function', tool_input={'input': 3}, log="\nInvoking: `magic_function` with `{'input': 3}`\n\n\n", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_gNzQT96XWoyZqVl1jI1yMnjy', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c9aa9c0491'}, id='run-dc7ce17d-02fd-4fdb-be82-7c902410b6b7', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_gNzQT96XWoyZqVl1jI1yMnjy', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{"input":3}', 'id': 'call_gNzQT96XWoyZqVl1jI1yMnjy', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_gNzQT96XWoyZqVl1jI1yMnjy')], 'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_gNzQT96XWoyZqVl1jI1yMnjy', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c9aa9c0491'}, id='run-dc7ce17d-02fd-4fdb-be82-7c902410b6b7', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_gNzQT96XWoyZqVl1jI1yMnjy', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{"input":3}', 'id': 'call_gNzQT96XWoyZqVl1jI1yMnjy', 'index': 0, 'type': 'tool_call_chunk'}])]}
{'steps': [AgentStep(action=ToolAgentAction(tool='magic_function', tool_input={'input': 3}, log="\nInvoking: `magic_function` with `{'input': 3}`\n\n\n", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_gNzQT96XWoyZqVl1jI1yMnjy', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c9aa9c0491'}, id='run-dc7ce17d-02fd-4fdb-be82-7c902410b6b7', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_gNzQT96XWoyZqVl1jI1yMnjy', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{"input":3}', 'id': 'call_gNzQT96XWoyZqVl1jI1yMnjy', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_gNzQT96XWoyZqVl1jI1yMnjy'), observation=5)], 'messages': [FunctionMessage(content='5', name='magic_function')]}
{'output': 'The value of `magic_function(3)` is 5.', 'messages': [AIMessage(content='The value of `magic_function(3)` is 5.')]}
```
### åœ¨ LangGraph ä¸­

åœ¨ LangGraph ä¸­ï¼Œäº‹æƒ…æ˜¯é€šè¿‡ [stream](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.CompiledGraph.stream) æˆ–å¼‚æ­¥ `astream` æ–¹æ³•æœ¬åœ°å¤„ç†çš„ã€‚


```python
from langgraph.prebuilt import create_react_agent
from langgraph.prebuilt.chat_agent_executor import AgentState

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant."),
        ("placeholder", "{messages}"),
    ]
)


def _modify_state_messages(state: AgentState):
    return prompt.invoke({"messages": state["messages"]}).to_messages()


app = create_react_agent(model, tools, state_modifier=_modify_state_messages)

for step in app.stream({"messages": [("human", query)]}, stream_mode="updates"):
    print(step)
```
```output
{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_I0nztlIcc0e9ry5dn53YLZUM', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 61, 'total_tokens': 75}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5f9bd87d-3692-4d13-8d27-1859e13e2156-0', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_I0nztlIcc0e9ry5dn53YLZUM', 'type': 'tool_call'}], usage_metadata={'input_tokens': 61, 'output_tokens': 14, 'total_tokens': 75})]}}
{'tools': {'messages': [ToolMessage(content='5', name='magic_function', tool_call_id='call_I0nztlIcc0e9ry5dn53YLZUM')]}}
{'agent': {'messages': [AIMessage(content='The value of `magic_function(3)` is 5.', response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 84, 'total_tokens': 98}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'stop', 'logprobs': None}, id='run-f6015ca6-93e5-45e8-8b28-b3f0a8d203dc-0', usage_metadata={'input_tokens': 84, 'output_tokens': 14, 'total_tokens': 98})]}}
```
## `return_intermediate_steps`

### åœ¨ LangChain ä¸­

åœ¨ AgentExecutor ä¸Šè®¾ç½®æ­¤å‚æ•°å…è®¸ç”¨æˆ·è®¿é—® intermediate_stepsï¼Œè¿™å°†ä»£ç†æ“ä½œï¼ˆä¾‹å¦‚ï¼Œå·¥å…·è°ƒç”¨ï¼‰ä¸å…¶ç»“æœé…å¯¹ã€‚



```python
agent_executor = AgentExecutor(agent=agent, tools=tools, return_intermediate_steps=True)
result = agent_executor.invoke({"input": query})
print(result["intermediate_steps"])
```
```output
[(ToolAgentAction(tool='magic_function', tool_input={'input': 3}, log="\nInvoking: `magic_function` with `{'input': 3}`\n\n\n", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_wjaAyTjI2LSYOq7C8QZYSxEs', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c9aa9c0491'}, id='run-99e06b70-1ef6-4761-834b-87b6c5252e20', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_wjaAyTjI2LSYOq7C8QZYSxEs', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{"input":3}', 'id': 'call_wjaAyTjI2LSYOq7C8QZYSxEs', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_wjaAyTjI2LSYOq7C8QZYSxEs'), 5)]
```
### åœ¨ LangGraph ä¸­

é»˜è®¤æƒ…å†µä¸‹ï¼ŒLangGraph ä¸­çš„ [react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent) å°†æ‰€æœ‰æ¶ˆæ¯é™„åŠ åˆ°ä¸­å¤®çŠ¶æ€ã€‚å› æ­¤ï¼Œåªéœ€æŸ¥çœ‹å®Œæ•´çŠ¶æ€å³å¯è½»æ¾æŸ¥çœ‹ä»»ä½•ä¸­é—´æ­¥éª¤ã€‚


```python
from langgraph.prebuilt import create_react_agent

app = create_react_agent(model, tools=tools)

messages = app.invoke({"messages": [("human", query)]})

messages
```



```output
{'messages': [HumanMessage(content='what is the value of magic_function(3)?', id='2d369331-8052-4167-bd85-9f6d8ad021ae'),
  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_oXiSQSe6WeWj7XIKXxZrO2IC', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-297e7fc9-726f-46a0-8c67-dc28ed1724d0-0', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_oXiSQSe6WeWj7XIKXxZrO2IC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69}),
  ToolMessage(content='5', name='magic_function', id='46370faf-9598-423c-b94b-aca8cb4f035d', tool_call_id='call_oXiSQSe6WeWj7XIKXxZrO2IC'),
  AIMessage(content='The value of `magic_function(3)` is 5.', response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 78, 'total_tokens': 92}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'stop', 'logprobs': None}, id='run-f48efaff-0c2c-4632-bbf9-7ee626f73d02-0', usage_metadata={'input_tokens': 78, 'output_tokens': 14, 'total_tokens': 92})]}
```


## `max_iterations`

### åœ¨ LangChain ä¸­

`AgentExecutor` å®ç°äº†ä¸€ä¸ª `max_iterations` å‚æ•°ï¼Œå…è®¸ç”¨æˆ·ä¸­æ­¢è¶…è¿‡æŒ‡å®šè¿­ä»£æ¬¡æ•°çš„è¿è¡Œã€‚


```python
@tool
def magic_function(input: str) -> str:
    """Applies a magic function to an input."""
    return "Sorry, there was an error. Please try again."


tools = [magic_function]
```


```python
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant. Respond only in Spanish."),
        ("human", "{input}"),
        # Placeholders fill up a **list** of messages
        ("placeholder", "{agent_scratchpad}"),
    ]
)

agent = create_tool_calling_agent(model, tools, prompt)
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    max_iterations=3,
)

agent_executor.invoke({"input": query})
```
```output


[1m> Entering new AgentExecutor chain...[0m
[32;1m[1;3m
Invoking: `magic_function` with `{'input': '3'}`


[0m[36;1m[1;3mSorry, there was an error. Please try again.[0m[32;1m[1;3mHubo un error al intentar obtener el valor de `magic_function(3)`. Â¿PodrÃ­as intentarlo de nuevo o proporcionar mÃ¡s detalles?[0m

[1m> Finished chain.[0m
```


```output
{'input': 'what is the value of magic_function(3)?',
 'output': 'Hubo un error al intentar obtener el valor de `magic_function(3)`. Â¿PodrÃ­as intentarlo de nuevo o proporcionar mÃ¡s detalles?'}
```


### åœ¨ LangGraph ä¸­

åœ¨ LangGraph ä¸­ï¼Œè¿™é€šè¿‡ `recursion_limit` é…ç½®å‚æ•°è¿›è¡Œæ§åˆ¶ã€‚

è¯·æ³¨æ„ï¼Œåœ¨ `AgentExecutor` ä¸­ï¼Œâ€œè¿­ä»£â€åŒ…æ‹¬å·¥å…·è°ƒç”¨å’Œæ‰§è¡Œçš„å®Œæ•´è½®æ¬¡ã€‚åœ¨ LangGraph ä¸­ï¼Œæ¯ä¸€æ­¥éƒ½è´¡çŒ®äºé€’å½’é™åˆ¶ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ä¹˜ä»¥äºŒï¼ˆå¹¶åŠ ä¸€ï¼‰ä»¥è·å¾—ç­‰æ•ˆç»“æœã€‚

å¦‚æœè¾¾åˆ°é€’å½’é™åˆ¶ï¼ŒLangGraph ä¼šå¼•å‘ç‰¹å®šçš„å¼‚å¸¸ç±»å‹ï¼Œæˆ‘ä»¬å¯ä»¥åƒå¤„ç† AgentExecutor ä¸€æ ·æ•è·å’Œç®¡ç†ã€‚


```python
from langgraph.errors import GraphRecursionError
from langgraph.prebuilt import create_react_agent

RECURSION_LIMIT = 2 * 3 + 1

app = create_react_agent(model, tools=tools)

try:
    for chunk in app.stream(
        {"messages": [("human", query)]},
        {"recursion_limit": RECURSION_LIMIT},
        stream_mode="values",
    ):
        print(chunk["messages"][-1])
except GraphRecursionError:
    print({"input": query, "output": "Agent stopped due to max iterations."})
```
```output
content='what is the value of magic_function(3)?' id='fe74bb30-45b8-4a40-a5ed-fd6678da5428'
content='' additional_kwargs={'tool_calls': [{'id': 'call_TNKfNy6fgZNdJAvHUMXwtp8f', 'function': {'arguments': '{"input":"3"}', 'name': 'magic_function'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-dad8bfc1-477c-40d2-9016-243d25c0dd13-0' tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_TNKfNy6fgZNdJAvHUMXwtp8f', 'type': 'tool_call'}] usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69}
content='Sorry, there was an error. Please try again.' name='magic_function' id='653226e0-3187-40be-a774-4c7c2612239e' tool_call_id='call_TNKfNy6fgZNdJAvHUMXwtp8f'
content='It looks like there was an issue with processing the request. Let me try that again.' additional_kwargs={'tool_calls': [{'id': 'call_K0wJ8fQLYGv8fYXY1Uo5U5sG', 'function': {'arguments': '{"input":"3"}', 'name': 'magic_function'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 88, 'total_tokens': 121}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-d4c85437-6625-4e57-81f9-86de6842be7b-0' tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_K0wJ8fQLYGv8fYXY1Uo5U5sG', 'type': 'tool_call'}] usage_metadata={'input_tokens': 88, 'output_tokens': 33, 'total_tokens': 121}
content='Sorry, there was an error. Please try again.' name='magic_function' id='9b530d03-95df-401e-bb4f-5cada1195033' tool_call_id='call_K0wJ8fQLYGv8fYXY1Uo5U5sG'
content='It seems that there is a persistent issue with processing the request. Let me attempt it one more time.' additional_kwargs={'tool_calls': [{'id': 'call_7ECwwNBDo4SH56oczErZJVRT', 'function': {'arguments': '{"input":"3"}', 'name': 'magic_function'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 143, 'total_tokens': 179}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-9f3f651e-a641-4112-99ed-d1ac11169582-0' tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_7ECwwNBDo4SH56oczErZJVRT', 'type': 'tool_call'}] usage_metadata={'input_tokens': 143, 'output_tokens': 36, 'total_tokens': 179}
content='Sorry, there was an error. Please try again.' name='magic_function' id='e4cd152b-4eb1-47df-ac76-f88e79adbe19' tool_call_id='call_7ECwwNBDo4SH56oczErZJVRT'
content="It seems there is a consistent issue with processing the request for the magic function. Let's try using a different approach to resolve this." additional_kwargs={'tool_calls': [{'id': 'call_DMAL0UwBRijzuPjCTSwR2r17', 'function': {'arguments': '{"input":"three"}', 'name': 'magic_function'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 201, 'total_tokens': 242}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c9aa9c0491', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-cd9f4e5c-f881-462c-abe3-890e73f46a01-0' tool_calls=[{'name': 'magic_function', 'args': {'input': 'three'}, 'id': 'call_DMAL0UwBRijzuPjCTSwR2r17', 'type': 'tool_call'}] usage_metadata={'input_tokens': 201, 'output_tokens': 41, 'total_tokens': 242}
{'input': 'what is the value of magic_function(3)?', 'output': 'Agent stopped due to max iterations.'}
```
## `max_execution_time`

### åœ¨ LangChain ä¸­

`AgentExecutor` å®ç°äº†ä¸€ä¸ª `max_execution_time` å‚æ•°ï¼Œå…è®¸ç”¨æˆ·ä¸­æ­¢è¶…è¿‡æ€»æ—¶é—´é™åˆ¶çš„è¿è¡Œã€‚


```python
import time


@tool
def magic_function(input: str) -> str:
    """Applies a magic function to an input."""
    time.sleep(2.5)
    return "Sorry, there was an error. Please try again."


tools = [magic_function]

agent = create_tool_calling_agent(model, tools, prompt)
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    max_execution_time=2,
    verbose=True,
)

agent_executor.invoke({"input": query})
```
```output


[1m> Entering new AgentExecutor chain...[0m
[32;1m[1;3m
Invoking: `magic_function` with `{'input': '3'}`


[0m[36;1m[1;3mSorry, there was an error. Please try again.[0m[32;1m[1;3m[0m

[1m> Finished chain.[0m
```


```output
{'input': 'what is the value of magic_function(3)?',
 'output': 'Agent stopped due to max iterations.'}
```


### åœ¨ LangGraph ä¸­

ä½¿ç”¨ LangGraph çš„ååº”ä»£ç†ï¼Œæ‚¨å¯ä»¥åœ¨ä¸¤ä¸ªçº§åˆ«ä¸Šæ§åˆ¶è¶…æ—¶ã€‚

æ‚¨å¯ä»¥è®¾ç½®ä¸€ä¸ª `step_timeout` æ¥é™åˆ¶æ¯ä¸ª **æ­¥éª¤**ï¼š


```python
from langgraph.prebuilt import create_react_agent

app = create_react_agent(model, tools=tools)
# Set the max timeout for each step here
app.step_timeout = 2

try:
    for chunk in app.stream({"messages": [("human", query)]}):
        print(chunk)
        print("------")
except TimeoutError:
    print({"input": query, "output": "Agent stopped due to a step timeout."})
```
```output
{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_o8Ym0u9UfzArhIm1lV7O0CXF', 'function': {'arguments': '{"input":"3"}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d9faf125-1ff8-4de2-a75b-97e07d28dc4d-0', tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_o8Ym0u9UfzArhIm1lV7O0CXF', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69})]}}
------
{'input': 'what is the value of magic_function(3)?', 'output': 'Agent stopped due to a step timeout.'}
```
è®¾ç½®æ•´ä¸ªè¿è¡Œçš„å•ä¸ªæœ€å¤§è¶…æ—¶çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ç›´æ¥ä½¿ç”¨ Python æ ‡å‡†åº“ [asyncio](https://docs.python.org/3/library/asyncio.html)ã€‚


```python
import asyncio

from langgraph.prebuilt import create_react_agent

app = create_react_agent(model, tools=tools)


async def stream(app, inputs):
    async for chunk in app.astream({"messages": [("human", query)]}):
        print(chunk)
        print("------")


try:
    task = asyncio.create_task(stream(app, {"messages": [("human", query)]}))
    await asyncio.wait_for(task, timeout=3)
except TimeoutError:
    print("Task Cancelled.")
```
```output
{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_gsGzyhyvR25iNV6W9VR2TIdQ', 'function': {'arguments': '{"input":"3"}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-9ad8f834-06c5-41cf-9eec-6b7e0f5e777e-0', tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_gsGzyhyvR25iNV6W9VR2TIdQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69})]}}
------
Task Cancelled.
```
## `early_stopping_method`

### åœ¨ LangChain ä¸­

ä½¿ç”¨ LangChain çš„ [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter)ï¼Œæ‚¨å¯ä»¥é…ç½®ä¸€ä¸ª [early_stopping_method](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.early_stopping_method)ï¼Œä»¥è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè¯´æ˜â€œä»£ç†å› è¿­ä»£é™åˆ¶æˆ–æ—¶é—´é™åˆ¶è€Œåœæ­¢ã€‚â€ï¼ˆ`


```python
<!--IMPORTS:[{"imported": "AgentExecutor", "source": "langchain.agents", "docs": "https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "create_tool_calling_agent", "source": "langchain.agents", "docs": "https://python.langchain.com/api_reference/langchain/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "tool", "source": "langchain_core.tools", "docs": "https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}]-->
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o")


prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant."),
        ("human", "{input}"),
        # Placeholders fill up a **list** of messages
        ("placeholder", "{agent_scratchpad}"),
    ]
)


@tool
def magic_function(input: int) -> int:
    """Applies a magic function to an input."""
    return "Sorry there was an error, please try again."


tools = [magic_function]

agent = create_tool_calling_agent(model, tools, prompt=prompt)
agent_executor = AgentExecutor(
    agent=agent, tools=tools, early_stopping_method="force", max_iterations=1
)

result = agent_executor.invoke({"input": query})
print("Output with early_stopping_method='force':")
print(result["output"])
```
```output
Output with early_stopping_method='force':
Agent stopped due to max iterations.
```
### åœ¨ LangGraph ä¸­

åœ¨ LangGraph ä¸­ï¼Œæ‚¨å¯ä»¥æ˜¾å¼å¤„ç†ä»£ç†å¤–çš„å“åº”è¡Œä¸ºï¼Œå› ä¸ºå¯ä»¥è®¿é—®å®Œæ•´çŠ¶æ€ã€‚


```python
from langgraph.errors import GraphRecursionError
from langgraph.prebuilt import create_react_agent

RECURSION_LIMIT = 2 * 1 + 1

app = create_react_agent(model, tools=tools)

try:
    for chunk in app.stream(
        {"messages": [("human", query)]},
        {"recursion_limit": RECURSION_LIMIT},
        stream_mode="values",
    ):
        print(chunk["messages"][-1])
except GraphRecursionError:
    print({"input": query, "output": "Agent stopped due to max iterations."})
```
```output
content='what is the value of magic_function(3)?' id='6487a942-0a9a-4e8a-9556-553a45fa9c5a'
content='' additional_kwargs={'tool_calls': [{'id': 'call_pe5KVY5No9iT4JWqrm5MwL1D', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-04147325-fb72-462a-a1d9-6aa4e86e3d8a-0' tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_pe5KVY5No9iT4JWqrm5MwL1D', 'type': 'tool_call'}] usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69}
content='Sorry there was an error, please try again.' name='magic_function' id='bc0bf58f-7c6c-42ed-a96d-a2afa79f16a9' tool_call_id='call_pe5KVY5No9iT4JWqrm5MwL1D'
content="It seems there was an issue with processing the request. I'll try again." additional_kwargs={'tool_calls': [{'id': 'call_5rV7k3g7oW38bD9KUTsSxK8l', 'function': {'arguments': '{"input":3}', 'name': 'magic_function'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 87, 'total_tokens': 117}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-6e43ffd4-fb6f-4222-8503-a50ae268c0be-0' tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_5rV7k3g7oW38bD9KUTsSxK8l', 'type': 'tool_call'}] usage_metadata={'input_tokens': 87, 'output_tokens': 30, 'total_tokens': 117}
{'input': 'what is the value of magic_function(3)?', 'output': 'Agent stopped due to max iterations.'}
```
## `trim_intermediate_steps`

### åœ¨ LangChain ä¸­

ä½¿ç”¨ LangChain çš„ [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor)ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ [trim_intermediate_steps](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.trim_intermediate_steps) ä¿®å‰ªé•¿æ—¶é—´è¿è¡Œä»£ç†çš„ä¸­é—´æ­¥éª¤ï¼Œè¯¥å‚æ•°å¯ä»¥æ˜¯ä¸€ä¸ªæ•´æ•°ï¼ˆè¡¨ç¤ºä»£ç†åº”ä¿ç•™æœ€å N æ­¥ï¼‰æˆ–ä¸€ä¸ªè‡ªå®šä¹‰å‡½æ•°ã€‚

ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä¿®å‰ªå€¼ï¼Œä½¿ä»£ç†ä»…æŸ¥çœ‹æœ€è¿‘çš„ä¸­é—´æ­¥éª¤ã€‚


```python
<!--IMPORTS:[{"imported": "AgentExecutor", "source": "langchain.agents", "docs": "https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "create_tool_calling_agent", "source": "langchain.agents", "docs": "https://python.langchain.com/api_reference/langchain/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "tool", "source": "langchain_core.tools", "docs": "https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "How to migrate from legacy LangChain agents to LangGraph"}]-->
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o")


prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant."),
        ("human", "{input}"),
        # Placeholders fill up a **list** of messages
        ("placeholder", "{agent_scratchpad}"),
    ]
)


magic_step_num = 1


@tool
def magic_function(input: int) -> int:
    """Applies a magic function to an input."""
    global magic_step_num
    print(f"Call number: {magic_step_num}")
    magic_step_num += 1
    return input + magic_step_num


tools = [magic_function]

agent = create_tool_calling_agent(model, tools, prompt=prompt)


def trim_steps(steps: list):
    # Let's give the agent amnesia
    return []


agent_executor = AgentExecutor(
    agent=agent, tools=tools, trim_intermediate_steps=trim_steps
)


query = "Call the magic function 4 times in sequence with the value 3. You cannot call it multiple times at once."

for step in agent_executor.stream({"input": query}):
    pass
```
```output
Call number: 1
Call number: 2
Call number: 3
Call number: 4
Call number: 5
Call number: 6
Call number: 7
Call number: 8
Call number: 9
Call number: 10
Call number: 11
Call number: 12
Call number: 13
Call number: 14
``````output
Stopping agent prematurely due to triggering stop condition
``````output
Call number: 15
```
### åœ¨LangGraphä¸­

æˆ‘ä»¬å¯ä»¥åƒä¹‹å‰ä¸€æ ·ä½¿ç”¨[`state_modifier`](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent)ï¼Œåœ¨ä¼ å…¥[æç¤ºè¯æ¨¡æ¿](#prompt-templates)æ—¶ã€‚


```python
from langgraph.errors import GraphRecursionError
from langgraph.prebuilt import create_react_agent
from langgraph.prebuilt.chat_agent_executor import AgentState

magic_step_num = 1


@tool
def magic_function(input: int) -> int:
    """Applies a magic function to an input."""
    global magic_step_num
    print(f"Call number: {magic_step_num}")
    magic_step_num += 1
    return input + magic_step_num


tools = [magic_function]


def _modify_state_messages(state: AgentState):
    # Give the agent amnesia, only keeping the original user query
    return [("system", "You are a helpful assistant"), state["messages"][0]]


app = create_react_agent(model, tools, state_modifier=_modify_state_messages)

try:
    for step in app.stream({"messages": [("human", query)]}, stream_mode="updates"):
        pass
except GraphRecursionError as e:
    print("Stopping agent prematurely due to triggering stop condition")
```
```output
Call number: 1
Call number: 2
Call number: 3
Call number: 4
Call number: 5
Call number: 6
Call number: 7
Call number: 8
Call number: 9
Call number: 10
Call number: 11
Call number: 12
Stopping agent prematurely due to triggering stop condition
```
## ä¸‹ä¸€æ­¥

æ‚¨ç°åœ¨å·²ç»å­¦ä¹ äº†å¦‚ä½•å°†æ‚¨çš„LangChainä»£ç†æ‰§è¡Œå™¨è¿ç§»åˆ°LangGraphã€‚

æ¥ä¸‹æ¥ï¼ŒæŸ¥çœ‹å…¶ä»–[LangGraphä½¿ç”¨æŒ‡å—](https://langchain-ai.github.io/langgraph/how-tos/)ã€‚
