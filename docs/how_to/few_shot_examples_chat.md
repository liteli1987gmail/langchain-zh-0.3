---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/how_to/few_shot_examples_chat.ipynb
sidebar_position: 2
---
# å¦‚ä½•åœ¨èŠå¤©æ¨¡å‹ä¸­ä½¿ç”¨å°‘é‡ç¤ºä¾‹

:::info Prerequisites

æœ¬æŒ‡å—å‡è®¾æ‚¨ç†Ÿæ‚‰ä»¥ä¸‹æ¦‚å¿µï¼š
- [æç¤ºè¯æ¨¡æ¿](/docs/concepts/#prompt-templates)
- [ç¤ºä¾‹é€‰æ‹©å™¨](/docs/concepts/#example-selectors)
- [èŠå¤©æ¨¡å‹](/docs/concepts/#chat-model)
- [å‘é‡å­˜å‚¨](/docs/concepts/#vector-stores)

:::

æœ¬æŒ‡å—æ¶µç›–å¦‚ä½•ä½¿ç”¨ç¤ºä¾‹è¾“å…¥å’Œè¾“å‡ºæç¤ºèŠå¤©æ¨¡å‹ã€‚å‘æ¨¡å‹æä¾›å°‘é‡è¿™æ ·çš„ç¤ºä¾‹ç§°ä¸ºå°‘é‡ç¤ºä¾‹æç¤ºï¼Œè¿™æ˜¯å¼•å¯¼ç”Ÿæˆçš„ä¸€ç§ç®€å•è€Œå¼ºå¤§çš„æ–¹æ³•ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹å¯ä»¥æ˜¾è‘—æé«˜æ¨¡å‹æ€§èƒ½ã€‚

ç›®å‰ä¼¼ä¹æ²¡æœ‰å…³äºå¦‚ä½•æœ€å¥½åœ°è¿›è¡Œå°‘é‡ç¤ºä¾‹æç¤ºçš„æ˜ç¡®å…±è¯†ï¼Œæœ€ä½³çš„æç¤ºç¼–å†™å¯èƒ½å› æ¨¡å‹è€Œå¼‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æä¾›äº†åƒ [FewShotChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate.html?highlight=fewshot#langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate) è¿™æ ·çš„å°‘é‡ç¤ºä¾‹æç¤ºæ¨¡æ¿ä½œä¸ºçµæ´»çš„èµ·ç‚¹ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦è¿›è¡Œä¿®æ”¹æˆ–æ›¿æ¢ã€‚

å°‘é‡ç¤ºä¾‹æç¤ºæ¨¡æ¿çš„ç›®æ ‡æ˜¯æ ¹æ®è¾“å…¥åŠ¨æ€é€‰æ‹©ç¤ºä¾‹ï¼Œç„¶åå°†ç¤ºä¾‹æ ¼å¼åŒ–ä¸ºæœ€ç»ˆæç¤ºä»¥æä¾›ç»™æ¨¡å‹ã€‚

**æ³¨æ„ï¼š** ä»¥ä¸‹ä»£ç ç¤ºä¾‹ä»…é€‚ç”¨äºèŠå¤©æ¨¡å‹ï¼Œå› ä¸º `FewShotChatMessagePromptTemplates` æ—¨åœ¨è¾“å‡ºæ ¼å¼åŒ–çš„ [èŠå¤©æ¶ˆæ¯](/docs/concepts/#message-types)ï¼Œè€Œä¸æ˜¯çº¯å­—ç¬¦ä¸²ã€‚æœ‰å…³ä¸å®Œæˆæ¨¡å‹ï¼ˆLLMsï¼‰å…¼å®¹çš„çº¯å­—ç¬¦ä¸²æ¨¡æ¿çš„ç±»ä¼¼å°‘é‡ç¤ºä¾‹æç¤ºï¼Œè¯·å‚è§ [å°‘é‡ç¤ºä¾‹æç¤ºæ¨¡æ¿](/docs/how_to/few_shot_examples/) æŒ‡å—ã€‚

## å›ºå®šç¤ºä¾‹

æœ€åŸºæœ¬ï¼ˆä¹Ÿæ˜¯æœ€å¸¸è§ï¼‰çš„å°‘é‡ç¤ºä¾‹æç¤ºæŠ€æœ¯æ˜¯ä½¿ç”¨å›ºå®šçš„æç¤ºç¤ºä¾‹ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ä¸€ä¸ªé“¾ï¼Œè¯„ä¼°å®ƒï¼Œå¹¶é¿å…åœ¨ç”Ÿäº§ä¸­æ‹…å¿ƒé¢å¤–çš„å¯å˜éƒ¨åˆ†ã€‚

æ¨¡æ¿çš„åŸºæœ¬ç»„ä»¶åŒ…æ‹¬ï¼š
- `examples`: åŒ…å«åœ¨æœ€ç»ˆæç¤ºä¸­çš„å­—å…¸ç¤ºä¾‹åˆ—è¡¨ã€‚
- `example_prompt`: é€šè¿‡å…¶ [`format_messages`](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html?highlight=format_messages#langchain_core.prompts.chat.ChatPromptTemplate.format_messages) æ–¹æ³•å°†æ¯ä¸ªç¤ºä¾‹è½¬æ¢ä¸º1ä¸ªæˆ–å¤šä¸ªæ¶ˆæ¯ã€‚ä¸€ä¸ªå¸¸è§çš„ç¤ºä¾‹æ˜¯å°†æ¯ä¸ªç¤ºä¾‹è½¬æ¢ä¸ºä¸€ä¸ªäººç±»æ¶ˆæ¯å’Œä¸€ä¸ªAIæ¶ˆæ¯å“åº”ï¼Œæˆ–è€…ä¸€ä¸ªäººç±»æ¶ˆæ¯åè·Ÿä¸€ä¸ªå‡½æ•°è°ƒç”¨æ¶ˆæ¯ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„æ¼”ç¤ºã€‚é¦–å…ˆï¼Œå®šä¹‰æ‚¨æƒ³è¦åŒ…å«çš„ç¤ºä¾‹ã€‚è®©æˆ‘ä»¬ç»™LLMä¸€ä¸ªä¸ç†Ÿæ‚‰çš„æ•°å­¦è¿ç®—ç¬¦ï¼Œç”¨â€œğŸ¦œâ€è¡¨æƒ…ç¬¦å·è¡¨ç¤ºï¼š


```python
%pip install -qU langchain langchain-openai langchain-chroma

import os
from getpass import getpass

if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"] = getpass()
```

å¦‚æœæˆ‘ä»¬å°è¯•è¯¢é—®æ¨¡å‹è¿™ä¸ªè¡¨è¾¾å¼çš„ç»“æœï¼Œå®ƒå°†å¤±è´¥ï¼š


```python
<!--IMPORTS:[{"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "How to use few shot examples in chat models"}]-->
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o-mini", temperature=0.0)

model.invoke("What is 2 ğŸ¦œ 9?")
```



```output
AIMessage(content='The expression "2 ğŸ¦œ 9" is not a standard mathematical operation or equation. It appears to be a combination of the number 2 and the parrot emoji ğŸ¦œ followed by the number 9. It does not have a specific mathematical meaning.', response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 17, 'total_tokens': 71}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-aad12dda-5c47-4a1e-9949-6fe94e03242a-0', usage_metadata={'input_tokens': 17, 'output_tokens': 54, 'total_tokens': 71})
```


ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å¦‚æœç»™å¤§å‹è¯­è¨€æ¨¡å‹ä¸€äº›ç¤ºä¾‹æ¥å¤„ç†ä¼šå‘ç”Ÿä»€ä¹ˆã€‚æˆ‘ä»¬å°†åœ¨ä¸‹é¢å®šä¹‰ä¸€äº›ï¼š


```python
<!--IMPORTS:[{"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to use few shot examples in chat models"}, {"imported": "FewShotChatMessagePromptTemplate", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate.html", "title": "How to use few shot examples in chat models"}]-->
from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate

examples = [
    {"input": "2 ğŸ¦œ 2", "output": "4"},
    {"input": "2 ğŸ¦œ 3", "output": "5"},
]
```

æ¥ä¸‹æ¥ï¼Œå°†å®ƒä»¬ç»„è£…æˆå°‘é‡ç¤ºä¾‹æç¤ºæ¨¡æ¿ã€‚


```python
# This is a prompt template used to format each individual example.
example_prompt = ChatPromptTemplate.from_messages(
    [
        ("human", "{input}"),
        ("ai", "{output}"),
    ]
)
few_shot_prompt = FewShotChatMessagePromptTemplate(
    example_prompt=example_prompt,
    examples=examples,
)

print(few_shot_prompt.invoke({}).to_messages())
```
```output
[HumanMessage(content='2 ğŸ¦œ 2'), AIMessage(content='4'), HumanMessage(content='2 ğŸ¦œ 3'), AIMessage(content='5')]
```
æœ€åï¼Œæˆ‘ä»¬å°†æœ€ç»ˆæç¤ºç»„è£…å¦‚ä¸‹ï¼Œå°† `few_shot_prompt` ç›´æ¥ä¼ é€’ç»™ `from_messages` å·¥å‚æ–¹æ³•ï¼Œå¹¶ä¸æ¨¡å‹ä¸€èµ·ä½¿ç”¨ï¼š


```python
final_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a wondrous wizard of math."),
        few_shot_prompt,
        ("human", "{input}"),
    ]
)
```

ç°åœ¨è®©æˆ‘ä»¬å‘æ¨¡å‹æå‡ºæœ€åˆçš„é—®é¢˜ï¼Œçœ‹çœ‹å®ƒçš„è¡¨ç°å¦‚ä½•ï¼š


```python
<!--IMPORTS:[{"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "How to use few shot examples in chat models"}]-->
from langchain_openai import ChatOpenAI

chain = final_prompt | model

chain.invoke({"input": "What is 2 ğŸ¦œ 9?"})
```



```output
AIMessage(content='11', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 60, 'total_tokens': 61}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5ec4e051-262f-408e-ad00-3f2ebeb561c3-0', usage_metadata={'input_tokens': 60, 'output_tokens': 1, 'total_tokens': 61})
```


æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ¨¡å‹ç°åœ¨å·²ç»ä»ç»™å®šçš„å°‘é‡ç¤ºä¾‹ä¸­æ¨æ–­å‡ºé¹¦é¹‰è¡¨æƒ…ç¬¦å·è¡¨ç¤ºåŠ æ³•ï¼

## åŠ¨æ€å°‘é‡ç¤ºä¾‹æç¤º

æœ‰æ—¶æ‚¨å¯èƒ½å¸Œæœ›æ ¹æ®è¾“å…¥ä»…é€‰æ‹©æ•´ä½“é›†åˆä¸­çš„å°‘é‡ç¤ºä¾‹è¿›è¡Œå±•ç¤ºã€‚ä¸ºæ­¤ï¼Œæ‚¨å¯ä»¥ç”¨ `example_selector` æ›¿æ¢ä¼ é€’ç»™ `FewShotChatMessagePromptTemplate` çš„ `examples`ã€‚å…¶ä»–ç»„ä»¶ä¸ä¸Šè¿°ç›¸åŒï¼æˆ‘ä»¬çš„åŠ¨æ€å°‘é‡ç¤ºä¾‹æç¤ºæ¨¡æ¿å¦‚ä¸‹æ‰€ç¤ºï¼š

- `example_selector`ï¼šè´Ÿè´£ä¸ºç»™å®šè¾“å…¥é€‰æ‹©å°‘é‡ç¤ºä¾‹ï¼ˆä»¥åŠè¿”å›çš„é¡ºåºï¼‰ã€‚è¿™äº›å®ç°äº† [BaseExampleSelector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.base.BaseExampleSelector.html?highlight=baseexampleselector#langchain_core.example_selectors.base.BaseExampleSelector) æ¥å£ã€‚ä¸€ä¸ªå¸¸è§çš„ä¾‹å­æ˜¯åŸºäºå‘é‡å­˜å‚¨çš„ [SemanticSimilarityExampleSelector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector.html?highlight=semanticsimilarityexampleselector#langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector)
- `example_prompt`ï¼šé€šè¿‡å…¶ [`format_messages`](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html?highlight=chatprompttemplate#langchain_core.prompts.chat.ChatPromptTemplate.format_messages) æ–¹æ³•å°†æ¯ä¸ªç¤ºä¾‹è½¬æ¢ä¸º 1 ä¸ªæˆ–å¤šä¸ªæ¶ˆæ¯ã€‚ä¸€ä¸ªå¸¸è§çš„ä¾‹å­æ˜¯å°†æ¯ä¸ªç¤ºä¾‹è½¬æ¢ä¸ºä¸€ä¸ªäººç±»æ¶ˆæ¯å’Œä¸€ä¸ª AI æ¶ˆæ¯å“åº”ï¼Œæˆ–è€…ä¸€ä¸ªäººç±»æ¶ˆæ¯åè·Ÿä¸€ä¸ªå‡½æ•°è°ƒç”¨æ¶ˆæ¯ã€‚

è¿™äº›å¯ä»¥å†æ¬¡ä¸å…¶ä»–æ¶ˆæ¯å’ŒèŠå¤©æ¨¡æ¿ç»„åˆï¼Œä»¥ç»„è£…æ‚¨çš„æœ€ç»ˆæç¤ºã€‚

è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªä½¿ç”¨ `SemanticSimilarityExampleSelector` çš„ç¤ºä¾‹æ¥æ¼”ç¤ºã€‚ç”±äºæ­¤å®ç°ä½¿ç”¨å‘é‡å­˜å‚¨æ ¹æ®è¯­ä¹‰ç›¸ä¼¼æ€§é€‰æ‹©ç¤ºä¾‹ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦å¡«å……å­˜å‚¨ã€‚è¿™é‡Œçš„åŸºæœ¬æ€æƒ³æ˜¯æˆ‘ä»¬å¸Œæœ›æœç´¢å¹¶è¿”å›ä¸æ–‡æœ¬è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹ï¼Œå› æ­¤æˆ‘ä»¬åµŒå…¥æç¤ºç¤ºä¾‹çš„ `values`ï¼Œè€Œä¸æ˜¯è€ƒè™‘é”®ï¼š


```python
<!--IMPORTS:[{"imported": "Chroma", "source": "langchain_chroma", "docs": "https://python.langchain.com/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html", "title": "How to use few shot examples in chat models"}, {"imported": "SemanticSimilarityExampleSelector", "source": "langchain_core.example_selectors", "docs": "https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector.html", "title": "How to use few shot examples in chat models"}, {"imported": "OpenAIEmbeddings", "source": "langchain_openai", "docs": "https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html", "title": "How to use few shot examples in chat models"}]-->
from langchain_chroma import Chroma
from langchain_core.example_selectors import SemanticSimilarityExampleSelector
from langchain_openai import OpenAIEmbeddings

examples = [
    {"input": "2 ğŸ¦œ 2", "output": "4"},
    {"input": "2 ğŸ¦œ 3", "output": "5"},
    {"input": "2 ğŸ¦œ 4", "output": "6"},
    {"input": "What did the cow say to the moon?", "output": "nothing at all"},
    {
        "input": "Write me a poem about the moon",
        "output": "One for the moon, and one for me, who are we to talk about the moon?",
    },
]

to_vectorize = [" ".join(example.values()) for example in examples]
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)
```

### åˆ›å»º `example_selector`

åˆ›å»ºäº†å‘é‡å­˜å‚¨åï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»º `example_selector`ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†å•ç‹¬è°ƒç”¨å®ƒï¼Œå¹¶å°† `k` è®¾ç½®ä¸ºä»…è·å–ä¸è¾“å…¥æœ€æ¥è¿‘çš„ä¸¤ä¸ªç¤ºä¾‹ã€‚


```python
example_selector = SemanticSimilarityExampleSelector(
    vectorstore=vectorstore,
    k=2,
)

# The prompt template will load examples by passing the input do the `select_examples` method
example_selector.select_examples({"input": "horse"})
```



```output
[{'input': 'What did the cow say to the moon?', 'output': 'nothing at all'},
 {'input': '2 ğŸ¦œ 4', 'output': '6'}]
```


### åˆ›å»ºæç¤ºæ¨¡æ¿

æˆ‘ä»¬ç°åœ¨ç»„è£…æç¤ºæ¨¡æ¿ï¼Œä½¿ç”¨ä¸Šé¢åˆ›å»ºçš„ `example_selector`ã€‚


```python
<!--IMPORTS:[{"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "How to use few shot examples in chat models"}, {"imported": "FewShotChatMessagePromptTemplate", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate.html", "title": "How to use few shot examples in chat models"}]-->
from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate

# Define the few-shot prompt.
few_shot_prompt = FewShotChatMessagePromptTemplate(
    # The input variables select the values to pass to the example_selector
    input_variables=["input"],
    example_selector=example_selector,
    # Define how each example will be formatted.
    # In this case, each example will become 2 messages:
    # 1 human, and 1 AI
    example_prompt=ChatPromptTemplate.from_messages(
        [("human", "{input}"), ("ai", "{output}")]
    ),
)

print(few_shot_prompt.invoke(input="What's 3 ğŸ¦œ 3?").to_messages())
```
```output
[HumanMessage(content='2 ğŸ¦œ 3'), AIMessage(content='5'), HumanMessage(content='2 ğŸ¦œ 4'), AIMessage(content='6')]
```
æˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªå°‘é‡ç¤ºä¾‹èŠå¤©æ¶ˆæ¯æç¤ºæ¨¡æ¿ä¼ é€’åˆ°å¦ä¸€ä¸ªèŠå¤©æç¤ºæ¨¡æ¿ä¸­ï¼š


```python
final_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a wondrous wizard of math."),
        few_shot_prompt,
        ("human", "{input}"),
    ]
)

print(few_shot_prompt.invoke(input="What's 3 ğŸ¦œ 3?"))
```
```output
messages=[HumanMessage(content='2 ğŸ¦œ 3'), AIMessage(content='5'), HumanMessage(content='2 ğŸ¦œ 4'), AIMessage(content='6')]
```
### ä¸èŠå¤©æ¨¡å‹ä¸€èµ·ä½¿ç”¨

æœ€åï¼Œæ‚¨å¯ä»¥å°†æ¨¡å‹è¿æ¥åˆ°å°‘é‡ç¤ºä¾‹æç¤ºã€‚


```python
chain = final_prompt | ChatOpenAI(model="gpt-4o-mini", temperature=0.0)

chain.invoke({"input": "What's 3 ğŸ¦œ 3?"})
```



```output
AIMessage(content='6', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 60, 'total_tokens': 61}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d1863e5e-17cd-4e9d-bf7a-b9f118747a65-0', usage_metadata={'input_tokens': 60, 'output_tokens': 1, 'total_tokens': 61})
```


## ä¸‹ä¸€æ­¥

æ‚¨ç°åœ¨å·²ç»å­¦ä¹ äº†å¦‚ä½•åœ¨èŠå¤©æç¤ºä¸­æ·»åŠ å°‘é‡ç¤ºä¾‹ã€‚

æ¥ä¸‹æ¥ï¼Œè¯·æŸ¥çœ‹æœ¬èŠ‚ä¸­å…³äºæç¤ºè¯æ¨¡æ¿çš„å…¶ä»–ä½¿ç”¨æ‰‹å†Œï¼Œç›¸å…³çš„å…³äº[ä½¿ç”¨æ–‡æœ¬å®Œæˆæ¨¡å‹è¿›è¡Œå°‘é‡ç¤ºä¾‹](/docs/how_to/few_shot_examples)çš„ä½¿ç”¨æ‰‹å†Œï¼Œæˆ–å…¶ä»–[ç¤ºä¾‹é€‰æ‹©å™¨ä½¿ç”¨æ‰‹å†Œ](/docs/how_to/example_selectors/)ã€‚
