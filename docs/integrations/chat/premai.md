---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/integrations/chat/premai.ipynb
sidebar_label: PremAI
---
# ChatPremAI

[PremAI](https://premai.io/) æ˜¯ä¸€ä¸ªä¸€ä½“åŒ–å¹³å°ï¼Œç®€åŒ–äº†ç”±ç”Ÿæˆå¼äººå·¥æ™ºèƒ½é©±åŠ¨çš„å¼ºå¤§ã€ç”Ÿäº§å°±ç»ªåº”ç”¨ç¨‹åºçš„åˆ›å»ºã€‚é€šè¿‡ç®€åŒ–å¼€å‘è¿‡ç¨‹ï¼ŒPremAI ä½¿æ‚¨èƒ½å¤Ÿä¸“æ³¨äºæå‡ç”¨æˆ·ä½“éªŒå’Œæ¨åŠ¨åº”ç”¨ç¨‹åºçš„æ•´ä½“å¢é•¿ã€‚æ‚¨å¯ä»¥å¿«é€Ÿå¼€å§‹ä½¿ç”¨æˆ‘ä»¬çš„å¹³å° [è¿™é‡Œ](https://docs.premai.io/quick-start)ã€‚

æœ¬ç¤ºä¾‹ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ LangChain ä¸ä¸åŒçš„èŠå¤©æ¨¡å‹è¿›è¡Œäº¤äº’ï¼Œä½¿ç”¨ `ChatPremAI`

### å®‰è£…å’Œè®¾ç½®

æˆ‘ä»¬é¦–å…ˆå®‰è£… `langchain` å’Œ `premai-sdk`ã€‚æ‚¨å¯ä»¥è¾“å…¥ä»¥ä¸‹å‘½ä»¤è¿›è¡Œå®‰è£…:

```bash
pip install premai langchain
```

åœ¨ç»§ç»­ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²åœ¨PremAIä¸Šåˆ›å»ºäº†å¸æˆ·å¹¶åˆ›å»ºäº†é¡¹ç›®ã€‚å¦‚æœæ²¡æœ‰ï¼Œè¯·å‚è€ƒ[å¿«é€Ÿå…¥é—¨](https://docs.premai.io/introduction)æŒ‡å—ä»¥å¼€å§‹ä½¿ç”¨PremAIå¹³å°ã€‚åˆ›å»ºæ‚¨çš„ç¬¬ä¸€ä¸ªé¡¹ç›®å¹¶è·å–æ‚¨çš„APIå¯†é’¥ã€‚


```python
<!--IMPORTS:[{"imported": "ChatPremAI", "source": "langchain_community.chat_models", "docs": "https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.premai.ChatPremAI.html", "title": "ChatPremAI"}, {"imported": "HumanMessage", "source": "langchain_core.messages", "docs": "https://python.langchain.com/api_reference/core/messages/langchain_core.messages.human.HumanMessage.html", "title": "ChatPremAI"}, {"imported": "SystemMessage", "source": "langchain_core.messages", "docs": "https://python.langchain.com/api_reference/core/messages/langchain_core.messages.system.SystemMessage.html", "title": "ChatPremAI"}]-->
from langchain_community.chat_models import ChatPremAI
from langchain_core.messages import HumanMessage, SystemMessage
```

### åœ¨LangChainä¸­è®¾ç½®PremAIå®¢æˆ·ç«¯

ä¸€æ—¦æˆ‘ä»¬å¯¼å…¥äº†æ‰€éœ€çš„æ¨¡å—ï¼Œè®©æˆ‘ä»¬è®¾ç½®æˆ‘ä»¬çš„å®¢æˆ·ç«¯ã€‚ç°åœ¨å‡è®¾æˆ‘ä»¬çš„`project_id`æ˜¯`8`ã€‚ä½†è¯·ç¡®ä¿ä½¿ç”¨æ‚¨çš„é¡¹ç›®IDï¼Œå¦åˆ™ä¼šæŠ›å‡ºé”™è¯¯ã€‚

è¦å°†langchainä¸premä¸€èµ·ä½¿ç”¨ï¼Œæ‚¨æ— éœ€ä¼ é€’ä»»ä½•æ¨¡å‹åç§°æˆ–è®¾ç½®ä»»ä½•å‚æ•°ä¸æˆ‘ä»¬çš„èŠå¤©å®¢æˆ·ç«¯ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒå°†ä½¿ç”¨åœ¨[LaunchPad](https://docs.premai.io/get-started/launchpad)ä¸­ä½¿ç”¨çš„æ¨¡å‹åç§°å’Œå‚æ•°ã€‚

> æ³¨æ„ï¼šå¦‚æœæ‚¨åœ¨è®¾ç½®å®¢æˆ·ç«¯æ—¶æ›´æ”¹`model`æˆ–ä»»ä½•å…¶ä»–å‚æ•°ï¼Œå¦‚`temperature`æˆ–`max_tokens`ï¼Œå®ƒå°†è¦†ç›–åœ¨LaunchPadä¸­ä½¿ç”¨çš„ç°æœ‰é»˜è®¤é…ç½®ã€‚


```python
import getpass
import os

# First step is to set up the env variable.
# you can also pass the API key while instantiating the model but this
# comes under a best practices to set it as env variable.

if os.environ.get("PREMAI_API_KEY") is None:
    os.environ["PREMAI_API_KEY"] = getpass.getpass("PremAI API Key:")
```


```python
# By default it will use the model which was deployed through the platform
# in my case it will is "gpt-4o"

chat = ChatPremAI(project_id=1234, model_name="gpt-4o")
```

### èŠå¤©å®Œæˆ

`ChatPremAI`æ”¯æŒä¸¤ç§æ–¹æ³•ï¼š`invoke`ï¼ˆä¸`generate`ç›¸åŒï¼‰å’Œ`stream`ã€‚

ç¬¬ä¸€ä¸ªå°†ç»™æˆ‘ä»¬ä¸€ä¸ªé™æ€ç»“æœã€‚è€Œç¬¬äºŒä¸ªå°†é€ä¸ªæµå¼ä¼ è¾“ä»¤ç‰Œã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•ç”Ÿæˆç±»ä¼¼èŠå¤©çš„å®Œæˆã€‚


```python
human_message = HumanMessage(content="Who are you?")

response = chat.invoke([human_message])
print(response.content)
```
```output
I am an AI language model created by OpenAI, designed to assist with answering questions and providing information based on the context provided. How can I help you today?
```
ä¸Šé¢çš„å†…å®¹çœ‹èµ·æ¥å¾ˆæœ‰è¶£ï¼Œå¯¹å§ï¼Ÿæˆ‘å°†æˆ‘çš„é»˜è®¤LaunchPadç³»ç»Ÿæç¤ºè®¾ç½®ä¸ºï¼š`æ€»æ˜¯å¬èµ·æ¥åƒä¸ªæµ·ç›—`ã€‚å¦‚æœéœ€è¦ï¼Œæ‚¨ä¹Ÿå¯ä»¥è¦†ç›–é»˜è®¤ç³»ç»Ÿæç¤ºã€‚ä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥è¿™æ ·åšçš„æ–¹æ³•ã€‚


```python
system_message = SystemMessage(content="You are a friendly assistant.")
human_message = HumanMessage(content="Who are you?")

chat.invoke([system_message, human_message])
```



```output
AIMessage(content="I'm your friendly assistant! How can I help you today?", response_metadata={'document_chunks': [{'repository_id': 1985, 'document_id': 1306, 'chunk_id': 173899, 'document_name': '[D] Difference between sparse and dense informatiâ€¦', 'similarity_score': 0.3209080100059509, 'content': "with the difference or anywhere\nwhere I can read about it?\n\n\n      17                  9\n\n\n      u/ScotiabankCanada        â€¢  Promoted\n\n\n                       Accelerate your study permit process\n                       with Scotiabank's Student GIC\n                       Program. We're here to help you turâ€¦\n\n\n                       startright.scotiabank.com         Learn More\n\n\n                            Add a Comment\n\n\nSort by:   Best\n\n\n      DinosParkour      â€¢ 1y ago\n\n\n     Dense Retrieval (DR) m"}]}, id='run-510bbd0e-3f8f-4095-9b1f-c2d29fd89719-0')
```


æ‚¨å¯ä»¥åœ¨è¿™é‡Œæä¾›ç³»ç»Ÿæç¤ºï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š


```python
chat.invoke([system_message, human_message], temperature=0.7, max_tokens=10, top_p=0.95)
```
```output
/home/anindya/prem/langchain/libs/community/langchain_community/chat_models/premai.py:355: UserWarning: WARNING: Parameter top_p is not supported in kwargs.
  warnings.warn(f"WARNING: Parameter {key} is not supported in kwargs.")
```


```output
AIMessage(content="Hello! I'm your friendly assistant. How can I", response_metadata={'document_chunks': [{'repository_id': 1985, 'document_id': 1306, 'chunk_id': 173899, 'document_name': '[D] Difference between sparse and dense informatiâ€¦', 'similarity_score': 0.3209080100059509, 'content': "with the difference or anywhere\nwhere I can read about it?\n\n\n      17                  9\n\n\n      u/ScotiabankCanada        â€¢  Promoted\n\n\n                       Accelerate your study permit process\n                       with Scotiabank's Student GIC\n                       Program. We're here to help you turâ€¦\n\n\n                       startright.scotiabank.com         Learn More\n\n\n                            Add a Comment\n\n\nSort by:   Best\n\n\n      DinosParkour      â€¢ 1y ago\n\n\n     Dense Retrieval (DR) m"}]}, id='run-c4b06b98-4161-4cca-8495-fd2fc98fa8f8-0')
```


> å¦‚æœæ‚¨è¦åœ¨æ­¤å¤„æ”¾ç½®ç³»ç»Ÿæç¤ºï¼Œåˆ™å®ƒå°†è¦†ç›–æ‚¨åœ¨ä»å¹³å°éƒ¨ç½²åº”ç”¨ç¨‹åºæ—¶å›ºå®šçš„ç³»ç»Ÿæç¤ºã€‚

### åŸç”ŸRAGæ”¯æŒä¸Premå­˜å‚¨åº“

Premå­˜å‚¨åº“å…è®¸ç”¨æˆ·ä¸Šä¼ æ–‡æ¡£ï¼ˆ.txtï¼Œ.pdfç­‰ï¼‰å¹¶å°†è¿™äº›å­˜å‚¨åº“è¿æ¥åˆ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚æ‚¨å¯ä»¥å°†Premå­˜å‚¨åº“è§†ä¸ºåŸç”ŸRAGï¼Œæ¯ä¸ªå­˜å‚¨åº“å¯ä»¥è¢«è§†ä¸ºä¸€ä¸ªå‘é‡æ•°æ®åº“ã€‚æ‚¨å¯ä»¥è¿æ¥å¤šä¸ªå­˜å‚¨åº“ã€‚æ‚¨å¯ä»¥åœ¨[è¿™é‡Œ](https://docs.premai.io/get-started/repositories)äº†è§£æ›´å¤šå…³äºå­˜å‚¨åº“çš„ä¿¡æ¯ã€‚

åœ¨LangChain Premä¸­ä¹Ÿæ”¯æŒå­˜å‚¨åº“ã€‚ä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥å¦‚ä½•æ“ä½œã€‚


```python
query = "Which models are used for dense retrieval"
repository_ids = [
    1985,
]
repositories = dict(ids=repository_ids, similarity_threshold=0.3, limit=3)
```

é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡ä¸€äº›å­˜å‚¨åº“IDæ¥å®šä¹‰æˆ‘ä»¬çš„å­˜å‚¨åº“ã€‚ç¡®ä¿è¿™äº›IDæ˜¯æœ‰æ•ˆçš„å­˜å‚¨åº“IDã€‚æ‚¨å¯ä»¥åœ¨[è¿™é‡Œ](https://docs.premai.io/get-started/repositories)äº†è§£æ›´å¤šå…³äºå¦‚ä½•è·å–å­˜å‚¨åº“IDçš„ä¿¡æ¯ã€‚

> è¯·æ³¨æ„ï¼šç±»ä¼¼äº`model_name`ï¼Œå½“æ‚¨è°ƒç”¨å‚æ•°`repositories`æ—¶ï¼Œæ‚¨å¯èƒ½ä¼šè¦†ç›–åœ¨å¯åŠ¨å¹³å°ä¸­è¿æ¥çš„å­˜å‚¨åº“ã€‚

ç°åœ¨ï¼Œæˆ‘ä»¬å°†å­˜å‚¨åº“ä¸æˆ‘ä»¬çš„èŠå¤©å¯¹è±¡è¿æ¥ï¼Œä»¥è°ƒç”¨åŸºäºRAGçš„ç”Ÿæˆã€‚


```python
import json

response = chat.invoke(query, max_tokens=100, repositories=repositories)

print(response.content)
print(json.dumps(response.response_metadata, indent=4))
```
```output
Dense retrieval models typically include:

1. **BERT-based Models**: Such as DPR (Dense Passage Retrieval) which uses BERT for encoding queries and passages.
2. **ColBERT**: A model that combines BERT with late interaction mechanisms.
3. **ANCE (Approximate Nearest Neighbor Negative Contrastive Estimation)**: Uses BERT and focuses on efficient retrieval.
4. **TCT-ColBERT**: A variant of ColBERT that uses a two-tower
{
    "document_chunks": [
        {
            "repository_id": 1985,
            "document_id": 1306,
            "chunk_id": 173899,
            "document_name": "[D] Difference between sparse and dense informati\u2026",
            "similarity_score": 0.3209080100059509,
            "content": "with the difference or anywhere\nwhere I can read about it?\n\n\n      17                  9\n\n\n      u/ScotiabankCanada        \u2022  Promoted\n\n\n                       Accelerate your study permit process\n                       with Scotiabank's Student GIC\n                       Program. We're here to help you tur\u2026\n\n\n                       startright.scotiabank.com         Learn More\n\n\n                            Add a Comment\n\n\nSort by:   Best\n\n\n      DinosParkour      \u2022 1y ago\n\n\n     Dense Retrieval (DR) m"
        }
    ]
}
```
> ç†æƒ³æƒ…å†µä¸‹ï¼Œæ‚¨ä¸éœ€è¦åœ¨æ­¤å¤„è¿æ¥å­˜å‚¨åº“IDä»¥è·å–æ£€ç´¢å¢å¼ºç”Ÿæˆã€‚å¦‚æœæ‚¨åœ¨Premå¹³å°ä¸­è¿æ¥äº†å­˜å‚¨åº“ï¼Œä»ç„¶å¯ä»¥è·å¾—ç›¸åŒçš„ç»“æœã€‚

### Premæ¨¡æ¿

ç¼–å†™æç¤ºè¯æ¨¡æ¿å¯èƒ½ä¼šéå¸¸éº»çƒ¦ã€‚æç¤ºè¯æ¨¡æ¿å¾ˆé•¿ï¼Œéš¾ä»¥ç®¡ç†ï¼Œå¹¶ä¸”å¿…é¡»ä¸æ–­è°ƒæ•´ä»¥æ”¹è¿›å¹¶åœ¨æ•´ä¸ªåº”ç”¨ç¨‹åºä¸­ä¿æŒä¸€è‡´ã€‚

ä½¿ç”¨ **Prem**ï¼Œç¼–å†™å’Œç®¡ç†æç¤ºè¯å˜å¾—éå¸¸ç®€å•ã€‚ [launchpad](https://docs.premai.io/get-started/launchpad) ä¸­çš„ **_æ¨¡æ¿_** é€‰é¡¹å¡å¸®åŠ©æ‚¨ç¼–å†™æ‰€éœ€çš„å¤šä¸ªæç¤ºè¯ï¼Œå¹¶åœ¨ SDK ä¸­ä½¿ç”¨å®ƒä»¬ï¼Œä½¿æ‚¨çš„åº”ç”¨ç¨‹åºèƒ½å¤Ÿä½¿ç”¨è¿™äº›æç¤ºè¯è¿è¡Œã€‚æ‚¨å¯ä»¥åœ¨ [è¿™é‡Œ](https://docs.premai.io/get-started/prem-templates) é˜…è¯»æ›´å¤šå…³äºæç¤ºè¯æ¨¡æ¿çš„ä¿¡æ¯ã€‚

è¦åœ¨ LangChain ä¸­åŸç”Ÿä½¿ç”¨ Prem æ¨¡æ¿ï¼Œæ‚¨éœ€è¦å°†ä¸€ä¸ª id ä¼ é€’ç»™ `HumanMessage`ã€‚è¿™ä¸ª id åº”è¯¥æ˜¯æ‚¨æç¤ºè¯æ¨¡æ¿å˜é‡çš„åç§°ã€‚`HumanMessage` ä¸­çš„ `content` åº”è¯¥æ˜¯è¯¥å˜é‡çš„å€¼ã€‚

å‡è®¾æ‚¨çš„æç¤ºè¯æ¨¡æ¿æ˜¯è¿™æ ·çš„ï¼š

```text
Say hello to my name and say a feel-good quote
from my age. My name is: {name} and age is {age}
```

æ‰€ä»¥ç°åœ¨æ‚¨çš„ human_messages åº”è¯¥çœ‹èµ·æ¥åƒï¼š


```python
human_messages = [
    HumanMessage(content="Shawn", id="name"),
    HumanMessage(content="22", id="age"),
]
```


å°†è¿™ä¸ª `human_messages` ä¼ é€’ç»™ ChatPremAI å®¢æˆ·ç«¯ã€‚è¯·æ³¨æ„ï¼šä¸è¦å¿˜è®°
ä¼ é€’é¢å¤–çš„ `template_id` ä»¥è°ƒç”¨ Prem æ¨¡æ¿çš„ç”Ÿæˆã€‚å¦‚æœæ‚¨ä¸çŸ¥é“ `template_id`ï¼Œå¯ä»¥åœ¨æˆ‘ä»¬çš„æ–‡æ¡£ä¸­äº†è§£æ›´å¤šä¿¡æ¯ [åœ¨è¿™é‡Œ](https://docs.premai.io/get-started/prem-templates)ã€‚è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š


```python
template_id = "78069ce8-xxxxx-xxxxx-xxxx-xxx"
response = chat.invoke([human_messages], template_id=template_id)
print(response.content)
```

Prem æ¨¡æ¿åŠŸèƒ½åœ¨æµå¼å¤„ç†ä¸­ä¹Ÿå¯ç”¨ã€‚

### æµå¼å¤„ç†

åœ¨æœ¬èŠ‚ä¸­ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨ langchain å’Œ PremAI æµå¼ä¼ è¾“ä»¤ç‰Œã€‚æ“ä½œæ–¹æ³•å¦‚ä¸‹ã€‚


```python
import sys

for chunk in chat.stream("hello how are you"):
    sys.stdout.write(chunk.content)
    sys.stdout.flush()
```
```output
It looks like your message got cut off. If you need information about Dense Retrieval (DR) or any other topic, please provide more details or clarify your question.
```
ä¸ä¸Šè¿°ç±»ä¼¼ï¼Œå¦‚æœæ‚¨æƒ³è¦†ç›–ç³»ç»Ÿæç¤ºå’Œç”Ÿæˆå‚æ•°ï¼Œæ‚¨éœ€è¦æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š


```python
import sys

# For some experimental reasons if you want to override the system prompt then you
# can pass that here too. However it is not recommended to override system prompt
# of an already deployed model.

for chunk in chat.stream(
    "hello how are you",
    system_prompt="act like a dog",
    temperature=0.7,
    max_tokens=200,
):
    sys.stdout.write(chunk.content)
    sys.stdout.flush()
```
```output
Woof! ğŸ¾ How can I help you today? Want to play fetch or maybe go for a walk ğŸ¶ğŸ¦´
```
### å‡½æ•°/å·¥å…·è°ƒç”¨

LangChain PremAI æ”¯æŒå·¥å…·/å‡½æ•°è°ƒç”¨ã€‚å·¥å…·/å‡½æ•°è°ƒç”¨å…è®¸æ¨¡å‹é€šè¿‡ç”Ÿæˆä¸ç”¨æˆ·å®šä¹‰çš„æ¨¡å¼åŒ¹é…çš„è¾“å‡ºï¼Œæ¥å“åº”ç»™å®šçš„æç¤ºã€‚

- æ‚¨å¯ä»¥åœ¨[æˆ‘ä»¬çš„æ–‡æ¡£ä¸­è¯¦ç»†äº†è§£å·¥å…·è°ƒç”¨](https://docs.premai.io/get-started/function-calling)ã€‚
- æ‚¨å¯ä»¥åœ¨[æ–‡æ¡£çš„è¿™ä¸€éƒ¨åˆ†](https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling)ä¸­äº†è§£æ›´å¤šå…³äº LangChain å·¥å…·è°ƒç”¨çš„ä¿¡æ¯ã€‚

**æ³¨æ„ï¼š**
å½“å‰ç‰ˆæœ¬çš„ LangChain ChatPremAI ä¸æ”¯æŒå¸¦æœ‰æµå¼æ”¯æŒçš„å‡½æ•°/å·¥å…·è°ƒç”¨ã€‚æµå¼æ”¯æŒå’Œå‡½æ•°è°ƒç”¨å°†å¾ˆå¿«æ¨å‡ºã€‚

#### å°†å·¥å…·ä¼ é€’ç»™æ¨¡å‹

ä¸ºäº†ä¼ é€’å·¥å…·å¹¶è®©å¤§å‹è¯­è¨€æ¨¡å‹é€‰æ‹©éœ€è¦è°ƒç”¨çš„å·¥å…·ï¼Œæˆ‘ä»¬éœ€è¦ä¼ é€’ä¸€ä¸ªå·¥å…·æ¨¡å¼ã€‚å·¥å…·æ¨¡å¼æ˜¯å‡½æ•°å®šä¹‰ä»¥åŠå…³äºå‡½æ•°çš„ä½œç”¨ã€æ¯ä¸ªå‚æ•°æ˜¯ä»€ä¹ˆç­‰çš„é€‚å½“æ–‡æ¡£å­—ç¬¦ä¸²ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›ç®€å•çš„ç®—æœ¯å‡½æ•°åŠå…¶æ¨¡å¼ã€‚

**æ³¨æ„ï¼š** åœ¨å®šä¹‰å‡½æ•°/å·¥å…·æ¨¡å¼æ—¶ï¼Œä¸è¦å¿˜è®°æ·»åŠ æœ‰å…³å‡½æ•°å‚æ•°çš„ä¿¡æ¯ï¼Œå¦åˆ™ä¼šæŠ›å‡ºé”™è¯¯ã€‚


```python
<!--IMPORTS:[{"imported": "tool", "source": "langchain_core.tools", "docs": "https://python.langchain.com/api_reference/core/tools/langchain_core.tools.convert.tool.html", "title": "ChatPremAI"}]-->
from langchain_core.tools import tool
from pydantic import BaseModel, Field


# Define the schema for function arguments
class OperationInput(BaseModel):
    a: int = Field(description="First number")
    b: int = Field(description="Second number")


# Now define the function where schema for argument will be OperationInput
@tool("add", args_schema=OperationInput, return_direct=True)
def add(a: int, b: int) -> int:
    """Adds a and b.

    Args:
        a: first int
        b: second int
    """
    return a + b


@tool("multiply", args_schema=OperationInput, return_direct=True)
def multiply(a: int, b: int) -> int:
    """Multiplies a and b.

    Args:
        a: first int
        b: second int
    """
    return a * b
```

#### å°†å·¥å…·æ¨¡å¼ä¸æˆ‘ä»¬çš„ LLM ç»‘å®š

æˆ‘ä»¬ç°åœ¨å°†ä½¿ç”¨ `bind_tools` æ–¹æ³•å°†ä¸Šè¿°å‡½æ•°è½¬æ¢ä¸ºâ€œå·¥å…·â€ï¼Œå¹¶å°†å…¶ä¸æ¨¡å‹ç»‘å®šã€‚è¿™æ„å‘³ç€æ¯æ¬¡è°ƒç”¨æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬éƒ½å°†ä¼ é€’è¿™äº›å·¥å…·ä¿¡æ¯ã€‚


```python
tools = [add, multiply]
llm_with_tools = chat.bind_tools(tools)
```

åœ¨æ­¤ä¹‹åï¼Œæˆ‘ä»¬ä»æ¨¡å‹ä¸­è·å–å“åº”ï¼Œè¯¥æ¨¡å‹ç°åœ¨ä¸å·¥å…·ç»‘å®šã€‚


```python
query = "What is 3 * 12? Also, what is 11 + 49?"

messages = [HumanMessage(query)]
ai_msg = llm_with_tools.invoke(messages)
```

æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œå½“æˆ‘ä»¬çš„èŠå¤©æ¨¡å‹ä¸å·¥å…·ç»‘å®šæ—¶ï¼Œæ ¹æ®ç»™å®šçš„æç¤ºï¼Œå®ƒä¼šè°ƒç”¨æ­£ç¡®çš„ä¸€ç»„å·¥å…·å¹¶æŒ‰é¡ºåºæ‰§è¡Œã€‚


```python
ai_msg.tool_calls
```



```output
[{'name': 'multiply',
  'args': {'a': 3, 'b': 12},
  'id': 'call_A9FL20u12lz6TpOLaiS6rFa8'},
 {'name': 'add',
  'args': {'a': 11, 'b': 49},
  'id': 'call_MPKYGLHbf39csJIyb5BZ9xIk'}]
```


æˆ‘ä»¬å°†ä¸Šè¿°æ¶ˆæ¯é™„åŠ åˆ° LLM ä¸Šï¼Œä½œä¸ºä¸Šä¸‹æ–‡ï¼Œä½¿ LLM æ„è¯†åˆ°å®ƒè°ƒç”¨äº†å“ªäº›å‡½æ•°ã€‚


```python
messages.append(ai_msg)
```

ç”±äºå·¥å…·è°ƒç”¨åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼Œå…¶ä¸­ï¼š

1. åœ¨æˆ‘ä»¬çš„ç¬¬ä¸€æ¬¡è°ƒç”¨ä¸­ï¼Œæˆ‘ä»¬æ”¶é›†äº† LLM å†³å®šä½¿ç”¨çš„æ‰€æœ‰å·¥å…·ï¼Œä»¥ä¾¿å®ƒå¯ä»¥è·å¾—ä½œä¸ºé™„åŠ ä¸Šä¸‹æ–‡çš„ç»“æœï¼Œä»è€Œæä¾›æ›´å‡†ç¡®ä¸”æ— å¹»è§‰çš„ç»“æœã€‚

2. åœ¨æˆ‘ä»¬çš„ç¬¬äºŒæ¬¡è°ƒç”¨ä¸­ï¼Œæˆ‘ä»¬å°†è§£æ LLM å†³å®šçš„é‚£ä¸€ç»„å·¥å…·å¹¶è¿è¡Œå®ƒä»¬ï¼ˆåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œå°†æ˜¯æˆ‘ä»¬å®šä¹‰çš„å‡½æ•°ï¼Œä½¿ç”¨ LLM æå–çš„å‚æ•°ï¼‰ï¼Œå¹¶å°†æ­¤ç»“æœä¼ é€’ç»™ LLMã€‚


```python
<!--IMPORTS:[{"imported": "ToolMessage", "source": "langchain_core.messages", "docs": "https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html", "title": "ChatPremAI"}]-->
from langchain_core.messages import ToolMessage

for tool_call in ai_msg.tool_calls:
    selected_tool = {"add": add, "multiply": multiply}[tool_call["name"].lower()]
    tool_output = selected_tool.invoke(tool_call["args"])
    messages.append(ToolMessage(tool_output, tool_call_id=tool_call["id"]))
```

æœ€åï¼Œæˆ‘ä»¬è°ƒç”¨ä¸å·¥å…·ç»‘å®šçš„ LLMï¼Œå¹¶å°†å‡½æ•°å“åº”æ·»åŠ åˆ°å®ƒçš„ä¸Šä¸‹æ–‡ä¸­ã€‚


```python
response = llm_with_tools.invoke(messages)
print(response.content)
```
```output
The final answers are:

- 3 * 12 = 36
- 11 + 49 = 60
```
### å®šä¹‰å·¥å…·æ¨¡å¼ï¼šPydantic ç±»

ä¸Šè¿°æˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ `tool` è£…é¥°å™¨å®šä¹‰æ¨¡å¼ï¼Œç„¶è€Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨ Pydantic ç­‰æ•ˆåœ°å®šä¹‰æ¨¡å¼ã€‚å½“ä½ çš„å·¥å…·è¾“å…¥æ›´å¤æ‚æ—¶ï¼ŒPydantic æ˜¯éå¸¸æœ‰ç”¨çš„ï¼š


```python
<!--IMPORTS:[{"imported": "PydanticToolsParser", "source": "langchain_core.output_parsers.openai_tools", "docs": "https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html", "title": "ChatPremAI"}]-->
from langchain_core.output_parsers.openai_tools import PydanticToolsParser


class add(BaseModel):
    """Add two integers together."""

    a: int = Field(..., description="First integer")
    b: int = Field(..., description="Second integer")


class multiply(BaseModel):
    """Multiply two integers together."""

    a: int = Field(..., description="First integer")
    b: int = Field(..., description="Second integer")


tools = [add, multiply]
```

ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥å°†å®ƒä»¬ç»‘å®šåˆ°èŠå¤©æ¨¡å‹å¹¶ç›´æ¥è·å–ç»“æœï¼š


```python
chain = llm_with_tools | PydanticToolsParser(tools=[multiply, add])
chain.invoke(query)
```



```output
[multiply(a=3, b=12), add(a=11, b=49)]
```


ç°åœ¨ï¼Œåƒä¸Šé¢æ‰€åšçš„é‚£æ ·ï¼Œæˆ‘ä»¬è§£æè¿™ä¸ªå¹¶è¿è¡Œè¿™äº›å‡½æ•°ï¼Œå†æ¬¡è°ƒç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä»¥è·å–ç»“æœã€‚


## ç›¸å…³

- èŠå¤©æ¨¡å‹ [æ¦‚å¿µæŒ‡å—](/docs/concepts/#chat-models)
- èŠå¤©æ¨¡å‹ [æ“ä½œæŒ‡å—](/docs/how_to/#chat-models)
