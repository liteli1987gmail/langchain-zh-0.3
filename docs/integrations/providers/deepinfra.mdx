# DeepInfra

> [DeepInfra](https://deepinfra.com/docs) 使我们能够轻松运行
> [最新的机器学习模型](https://deepinfra.com/models)。
> DeepInfra 处理与运行、扩展和监控相关的所有繁重工作，
> 用户可以专注于您的应用程序，并通过简单的 REST API 调用集成模型。

> DeepInfra 提供与 LangChain 集成的 [示例](https://deepinfra.com/docs/advanced/langchain)。

本页面介绍如何在 `LangChain` 中使用 `DeepInfra` 生态系统。
它分为两个部分：安装和设置，然后是对特定 DeepInfra 包装器的引用。

## 安装和设置

- 从此链接 [获取您的 DeepInfra API 密钥](https://deepinfra.com/)。
- 获取一个 DeepInfra API 密钥并将其设置为环境变量 (`DEEPINFRA_API_TOKEN`)

## 可用模型

DeepInfra 提供了一系列可部署的开源大型语言模型。

您可以查看支持的模型
[文本生成](https://deepinfra.com/models?type=text-generation) 和
[嵌入](https://deepinfra.com/models?type=embeddings)。

您可以查看 [请求和响应参数的列表](https://deepinfra.com/meta-llama/Llama-2-70b-chat-hf/api)。

聊天模型 [遵循 OpenAI API](https://deepinfra.com/meta-llama/Llama-2-70b-chat-hf/api?example=openai-http)


## 大型语言模型

查看 [使用示例](/docs/integrations/llms/deepinfra)。

```python
from langchain_community.llms import DeepInfra
```

## 嵌入模型

查看[使用示例](/docs/integrations/text_embedding/deepinfra)。

```python
from langchain_community.embeddings import DeepInfraEmbeddings
```

## 聊天模型

查看[使用示例](/docs/integrations/chat/deepinfra)。

```python
from langchain_community.chat_models import ChatDeepInfra
```
