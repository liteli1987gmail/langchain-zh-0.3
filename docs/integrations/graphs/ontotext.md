---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/integrations/graphs/ontotext.ipynb
---
# Ontotext GraphDB

>[Ontotext GraphDB](https://graphdb.ontotext.com/) æ˜¯ä¸€ä¸ªç¬¦åˆ [RDF](https://www.w3.org/RDF/) å’Œ [SPARQL](https://www.w3.org/TR/sparql11-query/) çš„å›¾æ•°æ®åº“å’ŒçŸ¥è¯†å‘ç°å·¥å…·ã€‚

>æœ¬ç¬”è®°æœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) æä¾›è‡ªç„¶è¯­è¨€æŸ¥è¯¢ (NLQ åˆ° SPARQLï¼Œä¹Ÿç§°ä¸º `text2sparql`) ä»¥ç”¨äº `Ontotext GraphDB`ã€‚

## GraphDB LLM åŠŸèƒ½

`GraphDB` æ”¯æŒä¸€äº› LLM é›†æˆåŠŸèƒ½ï¼Œå¦‚ [è¿™é‡Œ](https://github.com/w3c/sparql-dev/issues/193) æ‰€è¿°ï¼š

[gpt-queries](https://graphdb.ontotext.com/documentation/10.5/gpt-queries.html)

* é­”æ³•è°“è¯ï¼Œç”¨äºè¯·æ±‚ LLM æä¾›æ–‡æœ¬ã€åˆ—è¡¨æˆ–è¡¨æ ¼ï¼Œä½¿ç”¨æ¥è‡ªçŸ¥è¯†å›¾è°± (KG) çš„æ•°æ®
* æŸ¥è¯¢è§£é‡Š
* ç»“æœè§£é‡Šã€æ€»ç»“ã€æ”¹å†™ã€ç¿»è¯‘

[retrieval-graphdb-connector](https://graphdb.ontotext.com/documentation/10.5/retrieval-graphdb-connector.html)

* åœ¨å‘é‡æ•°æ®åº“ä¸­å¯¹çŸ¥è¯†å›¾è°±å®ä½“è¿›è¡Œç´¢å¼•
* æ”¯æŒä»»ä½•æ–‡æœ¬åµŒå…¥ç®—æ³•å’Œå‘é‡æ•°æ®åº“
* ä½¿ç”¨ä¸GraphDBä¸ºElasticã€Solrã€Luceneä½¿ç”¨çš„ç›¸åŒå¼ºå¤§è¿æ¥å™¨ï¼ˆç´¢å¼•ï¼‰è¯­è¨€
* RDFæ•°æ®æ›´æ”¹è‡ªåŠ¨åŒæ­¥åˆ°çŸ¥è¯†å›¾è°±å®ä½“ç´¢å¼•
* æ”¯æŒåµŒå¥—å¯¹è±¡ï¼ˆGraphDBç‰ˆæœ¬10.5ä¸­æ²¡æœ‰UIæ”¯æŒï¼‰
* å°†çŸ¥è¯†å›¾è°±å®ä½“åºåˆ—åŒ–ä¸ºæ–‡æœ¬ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼ˆä¾‹å¦‚ï¼Œå¯¹äºè‘¡è„é…’æ•°æ®é›†ï¼‰ï¼š

```
Franvino:
- is a RedWine.
- made from grape Merlo.
- made from grape Cabernet Franc.
- has sugar dry.
- has year 2012.
```

[ä¸å›¾å¯¹è¯](https://graphdb.ontotext.com/documentation/10.5/talk-to-graph.html)

* ä¸€ä¸ªä½¿ç”¨å®šä¹‰çš„çŸ¥è¯†å›¾è°±å®ä½“ç´¢å¼•çš„ç®€å•èŠå¤©æœºå™¨äºº


åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä¸ä½¿ç”¨GraphDB LLMé›†æˆï¼Œè€Œæ˜¯ä½¿ç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢ç”Ÿæˆ`SPARQL`ã€‚æˆ‘ä»¬å°†ä½¿ç”¨`æ˜Ÿçƒå¤§æˆ˜API`ï¼ˆ`SWAPI`ï¼‰æœ¬ä½“å’Œæ•°æ®é›†ï¼Œæ‚¨å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/Ontotext-AD/langchain-graphdb-qa-chain-demo/blob/main/starwars-data.trig)æŸ¥çœ‹ã€‚


## è®¾ç½®

æ‚¨éœ€è¦ä¸€ä¸ªæ­£åœ¨è¿è¡Œçš„GraphDBå®ä¾‹ã€‚æœ¬æ•™ç¨‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨[GraphDB Dockeré•œåƒ](https://hub.docker.com/r/ontotext/graphdb)åœ¨æœ¬åœ°è¿è¡Œæ•°æ®åº“ã€‚å®ƒæä¾›äº†ä¸€ä¸ªdocker composeè®¾ç½®ï¼Œå°†æ˜Ÿçƒå¤§æˆ˜æ•°æ®é›†å¡«å……åˆ°GraphDBä¸­ã€‚æ‰€æœ‰å¿…è¦çš„æ–‡ä»¶ï¼ŒåŒ…æ‹¬æ­¤ç¬”è®°æœ¬ï¼Œå¯ä»¥ä»[GitHubä»“åº“langchain-graphdb-qa-chain-demo](https://github.com/Ontotext-AD/langchain-graphdb-qa-chain-demo)ä¸‹è½½ã€‚

* å®‰è£…[Docker](https://docs.docker.com/get-docker/)ã€‚æœ¬æ•™ç¨‹æ˜¯ä½¿ç”¨Dockerç‰ˆæœ¬`24.0.7`åˆ›å»ºçš„ï¼Œè¯¥ç‰ˆæœ¬æ†ç»‘äº†[Docker Compose](https://docs.docker.com/compose/)ã€‚å¯¹äºæ—©æœŸçš„Dockerç‰ˆæœ¬ï¼Œæ‚¨å¯èƒ½éœ€è¦å•ç‹¬å®‰è£…Docker Composeã€‚
* åœ¨æ‚¨æœºå™¨ä¸Šçš„æœ¬åœ°æ–‡ä»¶å¤¹ä¸­å…‹éš†[GitHubä»“åº“langchain-graphdb-qa-chain-demo](https://github.com/Ontotext-AD/langchain-graphdb-qa-chain-demo)ã€‚
* ä½¿ç”¨ä»¥ä¸‹è„šæœ¬ä»åŒä¸€æ–‡ä»¶å¤¹å¯åŠ¨GraphDB
  
```
docker build --tag graphdb .
docker compose up -d graphdb
```

æ‚¨éœ€è¦ç­‰å¾…å‡ ç§’é’Ÿä»¥ä¾¿æ•°æ®åº“åœ¨`http://localhost:7200/`ä¸Šå¯åŠ¨ã€‚æ˜Ÿçƒå¤§æˆ˜æ•°æ®é›†`starwars-data.trig`ä¼šè‡ªåŠ¨åŠ è½½åˆ°`langchain`ä»“åº“ä¸­ã€‚å¯ä»¥ä½¿ç”¨æœ¬åœ°SPARQLç«¯ç‚¹`http://localhost:7200/repositories/langchain`æ¥è¿è¡ŒæŸ¥è¯¢ã€‚æ‚¨è¿˜å¯ä»¥ä»æ‚¨å–œæ¬¢çš„ç½‘é¡µæµè§ˆå™¨æ‰“å¼€GraphDBå·¥ä½œå°`http://localhost:7200/sparql`ï¼Œåœ¨è¿™é‡Œæ‚¨å¯ä»¥äº¤äº’å¼åœ°è¿›è¡ŒæŸ¥è¯¢ã€‚
* è®¾ç½®å·¥ä½œç¯å¢ƒ

å¦‚æœæ‚¨ä½¿ç”¨ `conda`ï¼Œè¯·åˆ›å»ºå¹¶æ¿€æ´»ä¸€ä¸ªæ–°çš„ conda ç¯å¢ƒï¼ˆä¾‹å¦‚ `conda create -n graph_ontotext_graphdb_qa python=3.9.18`ï¼‰ã€‚

å®‰è£…ä»¥ä¸‹åº“ï¼š

```
pip install jupyter==1.0.0
pip install openai==1.6.1
pip install rdflib==7.0.0
pip install langchain-openai==0.0.2
pip install langchain>=0.1.5
```

ä½¿ç”¨ Jupyter è¿è¡Œ
```
jupyter notebook
```

## æŒ‡å®šæœ¬ä½“

ä¸ºäº†ä½¿å¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆ SPARQLï¼Œå®ƒéœ€è¦äº†è§£çŸ¥è¯†å›¾è°±æ¨¡å¼ï¼ˆæœ¬ä½“ï¼‰ã€‚å¯ä»¥é€šè¿‡ `OntotextGraphDBGraph` ç±»çš„ä¸¤ä¸ªå‚æ•°ä¹‹ä¸€æä¾›ï¼š

* `query_ontology`ï¼šåœ¨ SPARQL ç«¯ç‚¹ä¸Šæ‰§è¡Œçš„ `CONSTRUCT` æŸ¥è¯¢ï¼Œè¿”å›çŸ¥è¯†å›¾è°±æ¨¡å¼è¯­å¥ã€‚æˆ‘ä»¬å»ºè®®å°†æœ¬ä½“å­˜å‚¨åœ¨å…¶è‡ªå·±çš„å‘½åå›¾ä¸­ï¼Œè¿™å°†ä½¿è·å–ç›¸å…³è¯­å¥å˜å¾—æ›´å®¹æ˜“ï¼ˆå¦‚ä¸‹ä¾‹æ‰€ç¤ºï¼‰ã€‚ä¸æ”¯æŒ `DESCRIBE` æŸ¥è¯¢ï¼Œå› ä¸º `DESCRIBE` è¿”å›å¯¹ç§°ç®€æ˜æœ‰ç•Œæè¿°ï¼ˆSCBDï¼‰ï¼Œå³ä¹ŸåŒ…æ‹¬ä¼ å…¥çš„ç±»é“¾æ¥ã€‚åœ¨å®ä¾‹æ•°é‡è¾¾åˆ°ç™¾ä¸‡çš„å¤§å‹å›¾ä¸­ï¼Œè¿™æ ·åšæ•ˆç‡ä¸é«˜ã€‚è¯·æŸ¥çœ‹ https://github.com/eclipse-rdf4j/rdf4j/issues/4857
* `local_file`ï¼šæœ¬åœ° RDF æœ¬ä½“æ–‡ä»¶ã€‚æ”¯æŒçš„ RDF æ ¼å¼æœ‰ `Turtle`ã€`RDF/XML`ã€`JSON-LD`ã€`N-Triples`ã€`Notation-3`ã€`Trig`ã€`Trix`ã€`N-Quads`ã€‚

åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œæœ¬ä½“è½¬å‚¨åº”ï¼š

* åŒ…å«è¶³å¤Ÿçš„å…³äºç±»ã€å±æ€§ã€å±æ€§é™„åŠ åˆ°ç±»çš„ä¿¡æ¯ï¼ˆä½¿ç”¨ rdfs:domainã€schema:domainIncludes æˆ– OWL é™åˆ¶ï¼‰å’Œåˆ†ç±»æ³•ï¼ˆé‡è¦ä¸ªä½“ï¼‰ã€‚
* ä¸åŒ…å«è¿‡äºå†—é•¿å’Œæ— å…³çš„å®šä¹‰å’Œç¤ºä¾‹ï¼Œè¿™äº›å†…å®¹å¯¹ SPARQL æ„å»ºæ²¡æœ‰å¸®åŠ©ã€‚


```python
<!--IMPORTS:[{"imported": "OntotextGraphDBGraph", "source": "langchain_community.graphs", "docs": "https://python.langchain.com/api_reference/community/graphs/langchain_community.graphs.ontotext_graphdb_graph.OntotextGraphDBGraph.html", "title": "Ontotext GraphDB"}]-->
from langchain_community.graphs import OntotextGraphDBGraph

# feeding the schema using a user construct query

graph = OntotextGraphDBGraph(
    query_endpoint="http://localhost:7200/repositories/langchain",
    query_ontology="CONSTRUCT {?s ?p ?o} FROM <https://swapi.co/ontology/> WHERE {?s ?p ?o}",
)
```


```python
# feeding the schema using a local RDF file

graph = OntotextGraphDBGraph(
    query_endpoint="http://localhost:7200/repositories/langchain",
    local_file="/path/to/langchain_graphdb_tutorial/starwars-ontology.nt",  # change the path here
)
```

æ— è®ºå¦‚ä½•ï¼Œæœ¬ä½“ï¼ˆæ¨¡å¼ï¼‰ä»¥ `Turtle` æ ¼å¼æä¾›ç»™å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå› ä¸ºå¸¦æœ‰é€‚å½“å‰ç¼€çš„ `Turtle` æ˜¯æœ€ç´§å‡‘ä¸”æœ€å®¹æ˜“è¢«å¤§å‹è¯­è¨€æ¨¡å‹è®°ä½çš„ã€‚

ã€Šæ˜Ÿçƒå¤§æˆ˜ã€‹çš„æœ¬ä½“æœ‰ç‚¹ä¸å¯»å¸¸ï¼Œå› ä¸ºå®ƒåŒ…å«äº†å¾ˆå¤šå…³äºç±»çš„ç‰¹å®šä¸‰å…ƒç»„ï¼Œä¾‹å¦‚ç‰©ç§ `:Aleena` ç”Ÿæ´»åœ¨ `<planet/38>` ä¸Šï¼Œå®ƒä»¬æ˜¯ `:Reptile` çš„å­ç±»ï¼Œå…·æœ‰æŸäº›å…¸å‹ç‰¹å¾ï¼ˆå¹³å‡èº«é«˜ã€å¹³å‡å¯¿å‘½ã€çš®è‚¤é¢œè‰²ï¼‰ï¼Œå¹¶ä¸”ç‰¹å®šä¸ªä½“ï¼ˆè§’è‰²ï¼‰æ˜¯è¯¥ç±»çš„ä»£è¡¨ï¼š


```
@prefix : <https://swapi.co/vocabulary/> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

:Aleena a owl:Class, :Species ;
    rdfs:label "Aleena" ;
    rdfs:isDefinedBy <https://swapi.co/ontology/> ;
    rdfs:subClassOf :Reptile, :Sentient ;
    :averageHeight 80.0 ;
    :averageLifespan "79" ;
    :character <https://swapi.co/resource/aleena/47> ;
    :film <https://swapi.co/resource/film/4> ;
    :language "Aleena" ;
    :planet <https://swapi.co/resource/planet/38> ;
    :skinColor "blue", "gray" .

    ...

 ```


ä¸ºäº†ä¿æŒæœ¬æ•™ç¨‹çš„ç®€å•æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨æœªåŠ å¯†çš„ GraphDBã€‚å¦‚æœ GraphDB æ˜¯åŠ å¯†çš„ï¼Œæ‚¨åº”è¯¥åœ¨åˆå§‹åŒ– `OntotextGraphDBGraph` ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡ 'GRAPHDB_USERNAME' å’Œ 'GRAPHDB_PASSWORD'ã€‚

```python
os.environ["GRAPHDB_USERNAME"] = "graphdb-user"
os.environ["GRAPHDB_PASSWORD"] = "graphdb-password"

graph = OntotextGraphDBGraph(
    query_endpoint=...,
    query_ontology=...
)
```


## é’ˆå¯¹ã€Šæ˜Ÿçƒå¤§æˆ˜ã€‹æ•°æ®é›†çš„é—®é¢˜å›ç­”

æˆ‘ä»¬ç°åœ¨å¯ä»¥ä½¿ç”¨ `OntotextGraphDBQAChain` æ¥æé—®ã€‚


```python
<!--IMPORTS:[{"imported": "OntotextGraphDBQAChain", "source": "langchain.chains", "docs": "https://python.langchain.com/api_reference/community/chains/langchain_community.chains.graph_qa.ontotext_graphdb.OntotextGraphDBQAChain.html", "title": "Ontotext GraphDB"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "Ontotext GraphDB"}]-->
import os

from langchain.chains import OntotextGraphDBQAChain
from langchain_openai import ChatOpenAI

# We'll be using an OpenAI model which requires an OpenAI API Key.
# However, other models are available as well:
# https://python.langchain.com/docs/integrations/chat/

# Set the environment variable `OPENAI_API_KEY` to your OpenAI API key
os.environ["OPENAI_API_KEY"] = "sk-***"

# Any available OpenAI model can be used here.
# We use 'gpt-4-1106-preview' because of the bigger context window.
# The 'gpt-4-1106-preview' model_name will deprecate in the future and will change to 'gpt-4-turbo' or similar,
# so be sure to consult with the OpenAI API https://platform.openai.com/docs/models for the correct naming.

chain = OntotextGraphDBQAChain.from_llm(
    ChatOpenAI(temperature=0, model_name="gpt-4-1106-preview"),
    graph=graph,
    verbose=True,
)
```

è®©æˆ‘ä»¬é—®ä¸€ä¸ªç®€å•çš„é—®é¢˜ã€‚


```python
chain.invoke({chain.input_key: "What is the climate on Tatooine?"})[chain.output_key]
```
```output


[1m> Entering new OntotextGraphDBQAChain chain...[0m
Generated SPARQL:
[32;1m[1;3mPREFIX : <https://swapi.co/vocabulary/>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>

SELECT ?climate
WHERE {
  ?planet rdfs:label "Tatooine" ;
          :climate ?climate .
}[0m

[1m> Finished chain.[0m
```


```output
'The climate on Tatooine is arid.'
```


è¿˜æœ‰ä¸€ä¸ªç¨å¾®å¤æ‚ä¸€ç‚¹çš„é—®é¢˜ã€‚


```python
chain.invoke({chain.input_key: "What is the climate on Luke Skywalker's home planet?"})[
    chain.output_key
]
```
```output


[1m> Entering new OntotextGraphDBQAChain chain...[0m
Generated SPARQL:
[32;1m[1;3mPREFIX : <https://swapi.co/vocabulary/>
PREFIX owl: <http://www.w3.org/2002/07/owl#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>

SELECT ?climate
WHERE {
  ?character rdfs:label "Luke Skywalker" .
  ?character :homeworld ?planet .
  ?planet :climate ?climate .
}[0m

[1m> Finished chain.[0m
```


```output
"The climate on Luke Skywalker's home planet is arid."
```


æˆ‘ä»¬è¿˜å¯ä»¥é—®æ›´å¤æ‚çš„é—®é¢˜ï¼Œæ¯”å¦‚


```python
chain.invoke(
    {
        chain.input_key: "What is the average box office revenue for all the Star Wars movies?"
    }
)[chain.output_key]
```
```output


[1m> Entering new OntotextGraphDBQAChain chain...[0m
Generated SPARQL:
[32;1m[1;3mPREFIX : <https://swapi.co/vocabulary/>
PREFIX owl: <http://www.w3.org/2002/07/owl#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

SELECT (AVG(?boxOffice) AS ?averageBoxOffice)
WHERE {
  ?film a :Film .
  ?film :boxOffice ?boxOfficeValue .
  BIND(xsd:decimal(?boxOfficeValue) AS ?boxOffice)
}
[0m

[1m> Finished chain.[0m
```


```output
'The average box office revenue for all the Star Wars movies is approximately 754.1 million dollars.'
```


## é“¾ä¿®æ”¹å™¨

Ontotext GraphDB QA é“¾å…è®¸å¯¹æç¤ºè¿›è¡Œä¼˜åŒ–ï¼Œä»¥è¿›ä¸€æ­¥æ”¹å–„æ‚¨çš„ QA é“¾å¹¶å¢å¼ºæ‚¨åº”ç”¨ç¨‹åºçš„æ•´ä½“ç”¨æˆ·ä½“éªŒã€‚


### "SPARQL ç”Ÿæˆ" æç¤º

è¯¥æç¤ºç”¨äºæ ¹æ®ç”¨æˆ·é—®é¢˜å’ŒçŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰æ¨¡å¼ç”Ÿæˆ SPARQL æŸ¥è¯¢ã€‚

- `sparql_generation_prompt`

é»˜è®¤å€¼ï¼š
  ````python
    GRAPHDB_SPARQL_GENERATION_TEMPLATE = """
    Write a SPARQL SELECT query for querying a graph database.
    The ontology schema delimited by triple backticks in Turtle format is:
    ```
    {schema}
    ```
    Use only the classes and properties provided in the schema to construct the SPARQL query.
    Do not use any classes or properties that are not explicitly provided in the SPARQL query.
    Include all necessary prefixes.
    Do not include any explanations or apologies in your responses.
    Do not wrap the query in backticks.
    Do not include any text except the SPARQL query generated.
    The question delimited by triple backticks is:
    ```
    {prompt}
    ```
    """
    GRAPHDB_SPARQL_GENERATION_PROMPT = PromptTemplate(
        input_variables=["schema", "prompt"],
        template=GRAPHDB_SPARQL_GENERATION_TEMPLATE,
    )
  ````

### "SPARQL ä¿®å¤" æç¤º

æœ‰æ—¶ï¼ŒLLM å¯èƒ½ä¼šç”Ÿæˆå¸¦æœ‰è¯­æ³•é”™è¯¯æˆ–ç¼ºå¤±å‰ç¼€ç­‰çš„ SPARQL æŸ¥è¯¢ã€‚è¯¥é“¾å°†å°è¯•é€šè¿‡æç¤º LLM è¿›è¡Œä¸€å®šæ¬¡æ•°çš„ä¿®æ­£ã€‚

- `sparql_fix_prompt`

é»˜è®¤å€¼ï¼š
  ````python
    GRAPHDB_SPARQL_FIX_TEMPLATE = """
    This following SPARQL query delimited by triple backticks
    ```
    {generated_sparql}
    ```
    is not valid.
    The error delimited by triple backticks is
    ```
    {error_message}
    ```
    Give me a correct version of the SPARQL query.
    Do not change the logic of the query.
    Do not include any explanations or apologies in your responses.
    Do not wrap the query in backticks.
    Do not include any text except the SPARQL query generated.
    The ontology schema delimited by triple backticks in Turtle format is:
    ```
    {schema}
    ```
    """
    
    GRAPHDB_SPARQL_FIX_PROMPT = PromptTemplate(
        input_variables=["error_message", "generated_sparql", "schema"],
        template=GRAPHDB_SPARQL_FIX_TEMPLATE,
    )
  ````

- `max_fix_retries`
  
é»˜è®¤å€¼ï¼š`5`

### "å›ç­”"æç¤º

è¯¥æç¤ºç”¨äºæ ¹æ®ä»æ•°æ®åº“è¿”å›çš„ç»“æœå’Œåˆå§‹ç”¨æˆ·é—®é¢˜æ¥å›ç­”é—®é¢˜ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒLLMè¢«æŒ‡ç¤ºä»…ä½¿ç”¨è¿”å›ç»“æœä¸­çš„ä¿¡æ¯ã€‚å¦‚æœç»“æœé›†ä¸ºç©ºï¼ŒLLMåº”å‘ŠçŸ¥æ— æ³•å›ç­”è¯¥é—®é¢˜ã€‚

- `qa_prompt`
  
é»˜è®¤å€¼ï¼š
  ````python
    GRAPHDB_QA_TEMPLATE = """Task: Generate a natural language response from the results of a SPARQL query.
    You are an assistant that creates well-written and human understandable answers.
    The information part contains the information provided, which you can use to construct an answer.
    The information provided is authoritative, you must never doubt it or try to use your internal knowledge to correct it.
    Make your response sound like the information is coming from an AI assistant, but don't add any information.
    Don't use internal knowledge to answer the question, just say you don't know if no information is available.
    Information:
    {context}
    
    Question: {prompt}
    Helpful Answer:"""
    GRAPHDB_QA_PROMPT = PromptTemplate(
        input_variables=["context", "prompt"], template=GRAPHDB_QA_TEMPLATE
    )
  ````

ä¸€æ—¦ä½ å®Œæˆäº†ä¸GraphDBçš„QAäº¤äº’ï¼Œå¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤å…³é—­Dockerç¯å¢ƒ
``
docker compose down -v --remove-orphans
``
ä»åŒ…å«Docker composeæ–‡ä»¶çš„ç›®å½•ä¸­è¿è¡Œã€‚
