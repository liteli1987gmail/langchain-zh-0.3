---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/integrations/callbacks/promptlayer.ipynb
---
# PromptLayer

>[PromptLayer](https://docs.promptlayer.com/introduction) æ˜¯ä¸€ä¸ªç”¨äºæç¤ºå·¥ç¨‹çš„å¹³å°ã€‚å®ƒè¿˜å¸®åŠ© LLM å¯è§‚å¯Ÿæ€§ï¼Œä»¥å¯è§†åŒ–è¯·æ±‚ã€ç‰ˆæœ¬æç¤ºå’Œè·Ÿè¸ªä½¿ç”¨æƒ…å†µã€‚
>
>è™½ç„¶ `PromptLayer` ç¡®å®æœ‰ä¸ LangChain ç›´æ¥é›†æˆçš„ LLMï¼ˆä¾‹å¦‚ [`PromptLayerOpenAI`](/docs/integrations/llms/promptlayer_openai)ï¼‰ï¼Œä½†ä½¿ç”¨å›è°ƒæ˜¯å°† `PromptLayer` ä¸ LangChain é›†æˆçš„æ¨èæ–¹å¼ã€‚

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»å¦‚ä½•è®¾ç½® `PromptLayerCallbackHandler`ã€‚

æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ [PromptLayer æ–‡æ¡£](https://docs.promptlayer.com/languages/langchain)ã€‚

## å®‰è£…å’Œè®¾ç½®


```python
%pip install --upgrade --quiet  langchain-community promptlayer --upgrade
```

### è·å– API å‡­è¯

å¦‚æœæ‚¨æ²¡æœ‰ PromptLayer è´¦æˆ·ï¼Œè¯·åœ¨ [promptlayer.com](https://www.promptlayer.com) ä¸Šåˆ›å»ºä¸€ä¸ªã€‚ç„¶åé€šè¿‡ç‚¹å‡»å¯¼èˆªæ ä¸­çš„è®¾ç½®é½¿è½®è·å– API å¯†é’¥ï¼Œå¹¶
å°†å…¶è®¾ç½®ä¸ºåä¸º `PROMPTLAYER_API_KEY` çš„ç¯å¢ƒå˜é‡


## ä½¿ç”¨æ–¹æ³•

`PromptLayerCallbackHandler` çš„å…¥é—¨ç›¸å½“ç®€å•ï¼Œå®ƒæ¥å—ä¸¤ä¸ªå¯é€‰å‚æ•°ï¼š
1. `pl_tags` - ä¸€ä¸ªå¯é€‰çš„å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œå°†ä½œä¸ºæ ‡ç­¾åœ¨ PromptLayer ä¸Šè¿›è¡Œè·Ÿè¸ªã€‚
2. `pl_id_callback` - ä¸€ä¸ªå¯é€‰çš„å‡½æ•°ï¼Œå°† `promptlayer_request_id` ä½œä¸ºå‚æ•°ã€‚æ­¤ ID å¯ä¸ PromptLayer çš„æ‰€æœ‰è·Ÿè¸ªåŠŸèƒ½ä¸€èµ·ä½¿ç”¨ï¼Œä»¥è·Ÿè¸ªå…ƒæ•°æ®ã€åˆ†æ•°å’Œæç¤ºä½¿ç”¨æƒ…å†µã€‚

## ç®€å•çš„ OpenAI ç¤ºä¾‹

åœ¨è¿™ä¸ªç®€å•çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ `PromptLayerCallbackHandler` ä¸ `ChatOpenAI`ã€‚æˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªåä¸º `chatopenai` çš„ PromptLayer æ ‡ç­¾


```python
<!--IMPORTS:[{"imported": "PromptLayerCallbackHandler", "source": "langchain_community.callbacks.promptlayer_callback", "docs": "https://python.langchain.com/api_reference/community/callbacks/langchain_community.callbacks.promptlayer_callback.PromptLayerCallbackHandler.html", "title": "PromptLayer"}]-->
import promptlayer  # Don't forget this ğŸ°
from langchain_community.callbacks.promptlayer_callback import (
    PromptLayerCallbackHandler,
)
```


```python
<!--IMPORTS:[{"imported": "HumanMessage", "source": "langchain_core.messages", "docs": "https://python.langchain.com/api_reference/core/messages/langchain_core.messages.human.HumanMessage.html", "title": "PromptLayer"}, {"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "PromptLayer"}]-->
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI

chat_llm = ChatOpenAI(
    temperature=0,
    callbacks=[PromptLayerCallbackHandler(pl_tags=["chatopenai"])],
)
llm_results = chat_llm.invoke(
    [
        HumanMessage(content="What comes after 1,2,3 ?"),
        HumanMessage(content="Tell me another joke?"),
    ]
)
print(llm_results)
```

## GPT4All ç¤ºä¾‹


```python
<!--IMPORTS:[{"imported": "GPT4All", "source": "langchain_community.llms", "docs": "https://python.langchain.com/api_reference/community/llms/langchain_community.llms.gpt4all.GPT4All.html", "title": "PromptLayer"}]-->
from langchain_community.llms import GPT4All

model = GPT4All(model="./models/gpt4all-model.bin", n_ctx=512, n_threads=8)
callbacks = [PromptLayerCallbackHandler(pl_tags=["langchain", "gpt4all"])]

response = model.invoke(
    "Once upon a time, ",
    config={"callbacks": callbacks},
)
```

## å®Œæ•´åŠŸèƒ½ç¤ºä¾‹

åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬è§£é”äº†æ›´å¤š `PromptLayer` çš„åŠŸèƒ½ã€‚

PromptLayer å…è®¸æ‚¨å¯è§†åŒ–åˆ›å»ºã€ç‰ˆæœ¬æ§åˆ¶å’Œè·Ÿè¸ªæç¤ºè¯æ¨¡æ¿ã€‚ä½¿ç”¨ [æç¤ºæ³¨å†Œè¡¨](https://docs.promptlayer.com/features/prompt-registry)ï¼Œæˆ‘ä»¬å¯ä»¥ä»¥ç¼–ç¨‹æ–¹å¼è·å–åä¸º `example` çš„æç¤ºè¯æ¨¡æ¿ã€‚

æˆ‘ä»¬è¿˜å®šä¹‰äº†ä¸€ä¸ª `pl_id_callback` å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥æ”¶ `promptlayer_request_id` å¹¶è®°å½•åˆ†æ•°ã€å…ƒæ•°æ®ä»¥åŠé“¾æ¥æ‰€ä½¿ç”¨çš„æç¤ºè¯æ¨¡æ¿ã€‚æœ‰å…³è·Ÿè¸ªçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… [æˆ‘ä»¬çš„æ–‡æ¡£](https://docs.promptlayer.com/features/prompt-history/request-id)ã€‚


```python
<!--IMPORTS:[{"imported": "OpenAI", "source": "langchain_openai", "docs": "https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html", "title": "PromptLayer"}]-->
from langchain_openai import OpenAI


def pl_id_callback(promptlayer_request_id):
    print("prompt layer id ", promptlayer_request_id)
    promptlayer.track.score(
        request_id=promptlayer_request_id, score=100
    )  # score is an integer 0-100
    promptlayer.track.metadata(
        request_id=promptlayer_request_id, metadata={"foo": "bar"}
    )  # metadata is a dictionary of key value pairs that is tracked on PromptLayer
    promptlayer.track.prompt(
        request_id=promptlayer_request_id,
        prompt_name="example",
        prompt_input_variables={"product": "toasters"},
        version=1,
    )  # link the request to a prompt template


openai_llm = OpenAI(
    model_name="gpt-3.5-turbo-instruct",
    callbacks=[PromptLayerCallbackHandler(pl_id_callback=pl_id_callback)],
)

example_prompt = promptlayer.prompts.get("example", version=1, langchain=True)
openai_llm.invoke(example_prompt.format(product="toasters"))
```

è¿™å°±æ˜¯æ‰€éœ€çš„ä¸€åˆ‡ï¼è®¾ç½®å®Œæˆåï¼Œæ‚¨çš„æ‰€æœ‰è¯·æ±‚å°†æ˜¾ç¤ºåœ¨ PromptLayer ä»ªè¡¨æ¿ä¸Šã€‚
æ­¤å›è°ƒä¹Ÿé€‚ç”¨äºåœ¨ LangChain ä¸Šå®ç°çš„ä»»ä½•å¤§å‹è¯­è¨€æ¨¡å‹ã€‚
