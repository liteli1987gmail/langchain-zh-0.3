---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/tutorials/extraction.ipynb
sidebar_position: 4
---
# æ„å»ºæå–é“¾

:::info Prerequisites

æœ¬æŒ‡å—å‡è®¾è¯»è€…ç†Ÿæ‚‰ä»¥ä¸‹æ¦‚å¿µï¼š

- [èŠå¤©æ¨¡å‹](/docs/concepts/#chat-models)
- [å·¥å…·](/docs/concepts/#tools)
- [å·¥å…·è°ƒç”¨](/docs/concepts/#function-tool-calling)

:::

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªé“¾ï¼Œä»¥ä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚

:::important
æœ¬æ•™ç¨‹ä»…é€‚ç”¨äºæ”¯æŒ **å·¥å…·è°ƒç”¨** çš„æ¨¡å‹
:::

## è®¾ç½®

### Jupyter Notebook

æœ¬æŒ‡å—ï¼ˆä»¥åŠæ–‡æ¡£ä¸­çš„å¤§å¤šæ•°å…¶ä»–æŒ‡å—ï¼‰ä½¿ç”¨ [Jupyter notebooks](https://jupyter.org/)ï¼Œå¹¶å‡è®¾è¯»è€…ä¹Ÿæ˜¯å¦‚æ­¤ã€‚Jupyter notebooks éå¸¸é€‚åˆå­¦ä¹ å¦‚ä½•ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç³»ç»Ÿï¼Œå› ä¸ºå¾ˆå¤šæ—¶å€™äº‹æƒ…å¯èƒ½ä¼šå‡ºé”™ï¼ˆæ„å¤–è¾“å‡ºã€APIæ•…éšœç­‰ï¼‰ï¼Œåœ¨äº¤äº’ç¯å¢ƒä¸­é˜…è¯»æŒ‡å—æ˜¯æ›´å¥½ç†è§£å®ƒä»¬çš„å¥½æ–¹æ³•ã€‚

è¿™äº›æ•™ç¨‹å¯èƒ½æœ€æ–¹ä¾¿åœ¨ Jupyter notebook ä¸­è¿è¡Œã€‚æœ‰å…³å¦‚ä½•å®‰è£…çš„è¯´æ˜ï¼Œè¯·å‚è§ [è¿™é‡Œ](https://jupyter.org/install)ã€‚

### å®‰è£…

è¦å®‰è£… LangChainï¼Œè¯·è¿è¡Œï¼š

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from "@theme/CodeBlock";

<Tabs>
  <TabItem value="pip" label="Pip" default>
    <CodeBlock language="bash">pip install langchain</CodeBlock>
  </TabItem>
  <TabItem value="conda" label="Conda">
    <CodeBlock language="bash">conda install langchain -c conda-forge</CodeBlock>
  </TabItem>
</Tabs>



æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§æˆ‘ä»¬çš„ [å®‰è£…æŒ‡å—](/docs/how_to/installation)ã€‚

### LangSmith

æ‚¨ä½¿ç”¨ LangChain æ„å»ºçš„è®¸å¤šåº”ç”¨ç¨‹åºå°†åŒ…å«å¤šä¸ªæ­¥éª¤å’Œå¤šæ¬¡è°ƒç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚
éšç€è¿™äº›åº”ç”¨ç¨‹åºå˜å¾—è¶Šæ¥è¶Šå¤æ‚ï¼Œèƒ½å¤Ÿæ£€æŸ¥æ‚¨çš„é“¾æˆ–ä»£ç†å†…éƒ¨ç©¶ç«Ÿå‘ç”Ÿäº†ä»€ä¹ˆå˜å¾—è‡³å…³é‡è¦ã€‚
æœ€å¥½çš„æ–¹æ³•æ˜¯ä½¿ç”¨ [LangSmith](https://smith.langchain.com)ã€‚

åœ¨æ‚¨é€šè¿‡ä¸Šè¿°é“¾æ¥æ³¨å†Œåï¼Œè¯·ç¡®ä¿è®¾ç½®æ‚¨çš„ç¯å¢ƒå˜é‡ä»¥å¼€å§‹è®°å½•è·Ÿè¸ªï¼š

```shell
export LANGCHAIN_TRACING_V2="true"
export LANGCHAIN_API_KEY="..."
```

æˆ–è€…ï¼Œå¦‚æœåœ¨ç¬”è®°æœ¬ä¸­ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼è®¾ç½®ï¼š

```python
import getpass
import os

os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()
```

## æ¨¡å¼

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æè¿°æˆ‘ä»¬æƒ³ä»æ–‡æœ¬ä¸­æå–çš„ä¿¡æ¯ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ Pydantic å®šä¹‰ä¸€ä¸ªç¤ºä¾‹æ¨¡å¼æ¥æå–ä¸ªäººä¿¡æ¯ã€‚


```python
from typing import Optional

from pydantic import BaseModel, Field


class Person(BaseModel):
    """Information about a person."""

    # ^ Doc-string for the entity Person.
    # This doc-string is sent to the LLM as the description of the schema Person,
    # and it can help to improve extraction results.

    # Note that:
    # 1. Each field is an `optional` -- this allows the model to decline to extract it!
    # 2. Each field has a `description` -- this description is used by the LLM.
    # Having a good description can help improve extraction results.
    name: Optional[str] = Field(default=None, description="The name of the person")
    hair_color: Optional[str] = Field(
        default=None, description="The color of the person's hair if known"
    )
    height_in_meters: Optional[str] = Field(
        default=None, description="Height measured in meters"
    )
```

å®šä¹‰æ¨¡å¼æ—¶æœ‰ä¸¤ä¸ªæœ€ä½³å®è·µï¼š

1. è®°å½• **å±æ€§** å’Œ **æ¨¡å¼** æœ¬èº«ï¼šè¿™äº›ä¿¡æ¯ä¼šå‘é€ç»™å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶ç”¨äºæé«˜ä¿¡æ¯æå–çš„è´¨é‡ã€‚
2. ä¸è¦å¼ºè¿«å¤§å‹è¯­è¨€æ¨¡å‹ç¼–é€ ä¿¡æ¯ï¼åœ¨ä¸Šé¢ï¼Œæˆ‘ä»¬å¯¹å±æ€§ä½¿ç”¨äº† `Optional`ï¼Œå…è®¸å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸çŸ¥é“ç­”æ¡ˆæ—¶è¾“å‡º `None`ã€‚

:::important
ä¸ºäº†è·å¾—æœ€ä½³æ€§èƒ½ï¼Œè¯·å¦¥å–„è®°å½•æ¨¡å¼ï¼Œå¹¶ç¡®ä¿æ¨¡å‹åœ¨æ–‡æœ¬ä¸­æ²¡æœ‰ä¿¡æ¯å¯æå–æ—¶ä¸ä¼šè¢«å¼ºè¿«è¿”å›ç»“æœã€‚
:::

## æå–å™¨

è®©æˆ‘ä»¬ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„æ¨¡å¼åˆ›å»ºä¸€ä¸ªä¿¡æ¯æå–å™¨ã€‚


```python
<!--IMPORTS:[{"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "Build an Extraction Chain"}, {"imported": "MessagesPlaceholder", "source": "langchain_core.prompts", "docs": "https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.MessagesPlaceholder.html", "title": "Build an Extraction Chain"}]-->
from typing import Optional

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from pydantic import BaseModel, Field

# Define a custom prompt to provide instructions and any additional context.
# 1) You can add examples into the prompt template to improve extraction quality
# 2) Introduce additional parameters to take context into account (e.g., include metadata
#    about the document from which the text was extracted.)
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are an expert extraction algorithm. "
            "Only extract relevant information from the text. "
            "If you do not know the value of an attribute asked to extract, "
            "return null for the attribute's value.",
        ),
        # Please see the how-to about improving performance with
        # reference examples.
        # MessagesPlaceholder('examples'),
        ("human", "{text}"),
    ]
)
```

æˆ‘ä»¬éœ€è¦ä½¿ç”¨æ”¯æŒå‡½æ•°/å·¥å…·è°ƒç”¨çš„æ¨¡å‹ã€‚

è¯·æŸ¥çœ‹[æ–‡æ¡£](/docs/concepts#function-tool-calling)ï¼Œäº†è§£å¯ä»¥ä¸æ­¤APIä¸€èµ·ä½¿ç”¨çš„ä¸€äº›æ¨¡å‹çš„åˆ—è¡¨ã€‚


```python
<!--IMPORTS:[{"imported": "ChatMistralAI", "source": "langchain_mistralai", "docs": "https://python.langchain.com/api_reference/mistralai/chat_models/langchain_mistralai.chat_models.ChatMistralAI.html", "title": "Build an Extraction Chain"}]-->
from langchain_mistralai import ChatMistralAI

llm = ChatMistralAI(model="mistral-large-latest", temperature=0)

runnable = prompt | llm.with_structured_output(schema=Person)
```
```output
/Users/harrisonchase/workplace/langchain/libs/core/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The method `ChatMistralAI.with_structured_output` is in beta. It is actively being worked on, so the API may change.
  warn_beta(
```
è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹


```python
text = "Alan Smith is 6 feet tall and has blond hair."
runnable.invoke({"text": text})
```



```output
Person(name='Alan Smith', hair_color='blond', height_in_meters='1.83')
```


:::important 

æå–æ˜¯ç”Ÿæˆæ€§çš„ ğŸ¤¯

å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯ç”Ÿæˆæ¨¡å‹ï¼Œå› æ­¤å®ƒä»¬å¯ä»¥åšä¸€äº›éå¸¸é…·çš„äº‹æƒ…ï¼Œæ¯”å¦‚æ­£ç¡®æå–ä»¥ç±³ä¸ºå•ä½çš„äººèº«é«˜
å°½ç®¡æä¾›çš„æ˜¯ä»¥è‹±å°ºä¸ºå•ä½çš„ï¼
:::

æˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°LangSmithçš„è¿½è¸ªè®°å½•ï¼šhttps://smith.langchain.com/public/44b69a63-3b3b-47b8-8a6d-61b46533f015/r

## å¤šä¸ªå®ä½“

åœ¨**å¤§å¤šæ•°æƒ…å†µä¸‹**ï¼Œæ‚¨åº”è¯¥æå–ä¸€ä¸ªå®ä½“åˆ—è¡¨ï¼Œè€Œä¸æ˜¯å•ä¸ªå®ä½“ã€‚

è¿™å¯ä»¥é€šè¿‡ä½¿ç”¨pydanticè½»æ¾å®ç°ï¼Œé€šè¿‡å°†æ¨¡å‹åµŒå¥—åœ¨å½¼æ­¤å†…éƒ¨ã€‚


```python
from typing import List, Optional

from pydantic import BaseModel, Field


class Person(BaseModel):
    """Information about a person."""

    # ^ Doc-string for the entity Person.
    # This doc-string is sent to the LLM as the description of the schema Person,
    # and it can help to improve extraction results.

    # Note that:
    # 1. Each field is an `optional` -- this allows the model to decline to extract it!
    # 2. Each field has a `description` -- this description is used by the LLM.
    # Having a good description can help improve extraction results.
    name: Optional[str] = Field(default=None, description="The name of the person")
    hair_color: Optional[str] = Field(
        default=None, description="The color of the person's hair if known"
    )
    height_in_meters: Optional[str] = Field(
        default=None, description="Height measured in meters"
    )


class Data(BaseModel):
    """Extracted data about people."""

    # Creates a model so that we can extract multiple entities.
    people: List[Person]
```

:::important
æå–å¯èƒ½åœ¨è¿™é‡Œå¹¶ä¸å®Œç¾ã€‚è¯·ç»§ç»­æŸ¥çœ‹å¦‚ä½•ä½¿ç”¨ **å‚è€ƒç¤ºä¾‹** æ¥æé«˜æå–è´¨é‡ï¼Œå¹¶æŸ¥çœ‹ **æŒ‡å—** éƒ¨åˆ†ï¼
:::


```python
runnable = prompt | llm.with_structured_output(schema=Data)
text = "My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me."
runnable.invoke({"text": text})
```



```output
Data(people=[Person(name='Jeff', hair_color=None, height_in_meters=None), Person(name='Anna', hair_color=None, height_in_meters=None)])
```


:::tip
å½“æ¨¡å¼é€‚åº”æå– **å¤šä¸ªå®ä½“** æ—¶ï¼Œå®ƒä¹Ÿå…è®¸æ¨¡å‹åœ¨æ²¡æœ‰ç›¸å…³ä¿¡æ¯çš„æƒ…å†µä¸‹æå– **æ— å®ä½“**ã€‚
é€šè¿‡æä¾›ä¸€ä¸ªç©ºåˆ—è¡¨æ¥å®ç°ã€‚

è¿™é€šå¸¸æ˜¯ä¸€ä¸ª **å¥½** çš„äº‹æƒ…ï¼å®ƒå…è®¸åœ¨å®ä½“ä¸ŠæŒ‡å®š **å¿…éœ€** å±æ€§ï¼Œè€Œä¸å¿…å¼ºåˆ¶æ¨¡å‹æ£€æµ‹è¯¥å®ä½“ã€‚
:::

æˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ° LangSmith è·Ÿè¸ªä¿¡æ¯ï¼š https://smith.langchain.com/public/7173764d-5e76-45fe-8496-84460bd9cdef/r

## ä¸‹ä¸€æ­¥

ç°åœ¨æ‚¨å·²ç»äº†è§£äº†ä½¿ç”¨ LangChain è¿›è¡Œæå–çš„åŸºç¡€çŸ¥è¯†ï¼Œæ‚¨å¯ä»¥ç»§ç»­è¿›è¡Œå…¶ä½™çš„ä½¿ç”¨æ‰‹å†Œï¼š

- [æ·»åŠ ç¤ºä¾‹](/docs/how_to/extraction_examples)ï¼šäº†è§£å¦‚ä½•ä½¿ç”¨ **å‚è€ƒç¤ºä¾‹** æ¥æé«˜æ€§èƒ½ã€‚
- [å¤„ç†é•¿æ–‡æœ¬](/docs/how_to/extraction_long_text)ï¼šå¦‚æœæ–‡æœ¬ä¸é€‚åˆ LLM çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œæ‚¨åº”è¯¥æ€ä¹ˆåšï¼Ÿ
- [ä½¿ç”¨è§£ææ–¹æ³•](/docs/how_to/extraction_parse)ï¼šä½¿ç”¨åŸºäºæç¤ºçš„æ–¹æ³•æå–ä¸æ”¯æŒ **å·¥å…·/å‡½æ•°è°ƒç”¨** çš„æ¨¡å‹ã€‚
